{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BACKGROUND:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, HondaWeb is the only known source of obtaining associate's basic information for almost any or all Honda associates from any Honda company.  Basic information such as company name, division, department, location, email, etc.  To discover what information can be obtained through HondaWeb profile pages, just simply observe your profile page.  Several attempts and inquires have been made to obtain a single source of profile information for any or all Honda associates, regardless of Honda company.  So far, HondaWeb appears to be the only good source.  To web scrape an associate's profile information from HondaWeb, besides the Python libraries, all that is needed is the associate's Windows log in user ID if they are non-American Honda associates.  For American Honda associates, their user ID is just their \"FirstName LastName\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if you are non-AHM associate, copy this URL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```https://somesite.com/REDACTED|AccessManagerMembershipProvider|```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then paste it into your browser and then add or type your Windows user ID at the end or right after the \"|\" symbol, then hit ENTER key.  You should then see your HondaWeb profile page.  For AHM associates, you would just type or enter their first name, space, then their last name instead, then hit the ENTER key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the knowledge above, if you belong to an internal organization where your membership or users can come from any Honda company, then all you need to have is a compiled list of their Windows user name/ID or first and last name (if AHM associate).  Then with this list, you can programmatically obtain their basic profile information with this web scraping technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python libraries that were installed that do not come with standard Python:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lxml\n",
    "- requests\n",
    "- tqdm\n",
    "- pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass                             # built-in Python library to enable hiding sensitive info such as password\n",
    "from lxml import html                                   # Library to web scrape HTML pages                   \n",
    "from requests.adapters import HTTPAdapter               # Needed to avoid max retries errors\n",
    "from requests.packages.urllib3.util.retry import Retry  # Needed to avoid max retries erros\n",
    "from tqdm import tqdm_notebook                          # library to embed progress bar\n",
    "import pandas as pd                                     # Library for working with heterogenous tabular data\n",
    "import requests                                         # Needed to handle HTTP requests and maintaining session\n",
    "import sqlite3                                          # Members Windows user IDs are saved in a sqlite3 database\n",
    "pd.options.display.max_colwidth=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python libraries that were installed that do not come with standard Python:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lxml\n",
    "- requests\n",
    "- tqdm\n",
    "- pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain a  list of BRAIN BRG Member's Windows user ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(r'\\\\some_site.honda.com\\REDACTED\\database.db')\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "    RTRIM(OPRID) as OPRID\n",
    "\n",
    "FROM\n",
    "    members\n",
    "\n",
    "WHERE\n",
    "    Member = 'X'\n",
    "\"\"\"\n",
    "\n",
    "members = pd.read_sql_query(sql, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at our list of Windows user IDs of BRAIN members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members.OPRID.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping Part Using Python lxml library and request library to authenticate into HondaWeb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Alternatively, we could use Selenium library to authenticate.  Using Selenium would be much easier to authenticate as you do not need to reverse engineer how to authenticate into HondaWeb which requires computer networking knowledge and recording the network traffic of the browser using the browser's developer tools.  An example using Selenium instead will be provided at a later time.  The disadvantage of using Selenium is that almost always, web scraping will be slower compared to a non-Selenium based solution since with Selenium, you are essentially using a stripped down version of a browser to perform the web scraping tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows NT User Name: ········\n",
      "Windows NT Password: ········\n",
      "NOTE: If proxy error occurs after submitting login, re-try again.\n",
      "Submitted login\n",
      "Passed authentication #1\n",
      "Passed authentication #2\n",
      "Passed authentication #3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721c1a055eeb4daf963f2c7c7b431611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Looping thru members...', max=153, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# To avoid \"max retries exceeded for URL\" error, we need to add retry connects and add delay (0.5 second)\n",
    "# Visit this StackOverflow discussion for background info:\n",
    "# https://stackoverflow.com/questions/23013220/max-retries-exceeded-with-url-in-requests\n",
    "s = requests.session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "s.mount('http://', adapter)\n",
    "s.mount('https://', adapter)\n",
    "\n",
    "# Using the browser's network monitoring tool, the following URLs are needed to \"authenticate\"\n",
    "login_url = 'https://some_site.com/REDACTED/default.aspx'\n",
    "login_url2 = 'https://some_site.com/REDACTED/15/Authenticate.aspx?Source=/'\n",
    "login_url3 = 'https://some_site.com/REDACTED/accessmanagersignin.aspx?ReturnUrl=/_layouts/15/Authenticate.aspx?Source=%2F&Source=/'\n",
    "login_url4 = 'https://some_site.com/REDACTED/15/Authenticate.aspx?Source=/'\n",
    "\n",
    "username = getpass('Windows NT User Name: ')\n",
    "password = getpass('Windows NT Password: ')\n",
    "\n",
    "credentials = {\n",
    "    'username': username,\n",
    "    'password': password,\n",
    "    'login_referrer': '',\n",
    "    'login': 'Y'\n",
    "}\n",
    "\n",
    "# Now visit the necessary 4 URLs to authenticate\n",
    "request1 = s.post(login_url, data=credentials)\n",
    "print('NOTE: If proxy error occurs after submitting login, re-try again.')\n",
    "print('Submitted login')\n",
    "request2 = s.get(login_url2)\n",
    "print('Passed authentication #1')\n",
    "request3 = s.get(login_url3)\n",
    "print('Passed authentication #2')\n",
    "request4 = s.get(login_url4)\n",
    "print('Passed authentication #3')\n",
    "\n",
    "# Initialize Python lists to contain the data we want to capture\n",
    "first_last_name_list = []\n",
    "company_list = []\n",
    "division_list = []\n",
    "department_list = []\n",
    "office_location_list = []\n",
    "email_list = []\n",
    "skills_list = []\n",
    "interests_list = []\n",
    "profile_url_list = []\n",
    "\n",
    "# This is the \"base\" URL needed to append or concatenate the member's Windows user ID with\n",
    "base_profile_url = 'https://somesite.com/REDACTED|AccessManagerMembershipProvider|'\n",
    "\n",
    "# Identify yourself just in case HondaWeb server has \"monitoring\" systems to track malicious threats\n",
    "headers = {'user-agent' : 'Mozilla/5.0 john_smith@somecompany.com'}\n",
    "\n",
    "# Now loop through the list of members' Windows user IDs and visit their HondaWeb profile page\n",
    "# and extract their data with lxml's XPath query language\n",
    "for member in tqdm_notebook(members.OPRID, desc='Looping thru members...'):\n",
    "    member_url = base_profile_url + member\n",
    "    request = s.get(member_url, headers=headers)\n",
    "    profile_html = html.fromstring(request.content)\n",
    "\n",
    "    first_last_name_div = profile_html.xpath('//div[@id=\"ctl00_SPWebPartManager1_g_402dacf0_24c9_49f7_b128_9a852fc0ae8a_ProfileViewer_PreferredName\"] \\\n",
    "                                        /span[@class=\"ms-tableCell ms-profile-detailsValue\"]/text()')\n",
    "    company_div = profile_html.xpath('//div[@id=\"ctl00_SPWebPartManager1_g_402dacf0_24c9_49f7_b128_9a852fc0ae8a_ProfileViewer_HondaCompanyName\"] \\\n",
    "                                    /span[@class=\"ms-tableCell ms-profile-detailsValue\"]/text()')\n",
    "    division_div = profile_html.xpath('//div[@id=\"ctl00_SPWebPartManager1_g_402dacf0_24c9_49f7_b128_9a852fc0ae8a_ProfileViewer_HondaDivisionName\"] \\\n",
    "                                    /span[@class=\"ms-tableCell ms-profile-detailsValue\"]/text()')\n",
    "    department_div = profile_html.xpath('//div[@id=\"ctl00_SPWebPartManager1_g_402dacf0_24c9_49f7_b128_9a852fc0ae8a_ProfileViewer_HondaDepartmentName\"] \\\n",
    "                                    /span[@class=\"ms-tableCell ms-profile-detailsValue\"]/text()')\n",
    "    office_loc_div = profile_html.xpath('//div[@id=\"ctl00_SPWebPartManager1_g_402dacf0_24c9_49f7_b128_9a852fc0ae8a_ProfileViewer_SPS-Location\"] \\\n",
    "                                    /span[@class=\"ms-tableCell ms-profile-detailsValue\"]/text()')\n",
    "    email_span = profile_html.xpath('//span[@id=\"ProfileViewer_ValueWorkEmail\"]/text()')\n",
    "    skills_div = profile_html.xpath('//div[@id=\"ctl00_SPWebPartManager1_g_402dacf0_24c9_49f7_b128_9a852fc0ae8a_ProfileViewer_SPS-Skills\"] \\\n",
    "                                    /span[@class=\"ms-tableCell ms-profile-detailsValue\"]/text()')\n",
    "    interests_div = profile_html.xpath('//div[@id=\"ctl00_SPWebPartManager1_g_402dacf0_24c9_49f7_b128_9a852fc0ae8a_ProfileViewer_SPS-Interests\"] \\\n",
    "                                    /span[@class=\"ms-tableCell ms-profile-detailsValue\"]/text()')\n",
    "    \n",
    "    # With each member's data, we will add them/append to their respective Python list\n",
    "    if first_last_name_div:\n",
    "        first_last_name_list.append(first_last_name_div[0])\n",
    "    else:\n",
    "        first_last_name_list.append('')\n",
    "    \n",
    "    if company_div:\n",
    "        company_list.append(company_div[0])\n",
    "    else:\n",
    "        company_list.append('')\n",
    "        \n",
    "    if division_div:\n",
    "        division_list.append(division_div[0])\n",
    "    else:\n",
    "        division_list.append('')\n",
    "        \n",
    "    if department_div:\n",
    "        department_list.append(department_div[0])\n",
    "    else:\n",
    "        department_list.append('')\n",
    "        \n",
    "    if office_loc_div:\n",
    "        office_location_list.append(office_loc_div[0])\n",
    "    else:\n",
    "        office_location_list.append('')\n",
    "    \n",
    "    if email_span:\n",
    "        email_list.append(email_span[0].lower())  # Discovered that for some reason, some emails can have mix cases\n",
    "    else:\n",
    "        email_list.append('')\n",
    "    \n",
    "    if skills_div:\n",
    "        skills_list.append(skills_div[0])\n",
    "    else:\n",
    "        skills_list.append('')\n",
    "        \n",
    "    if interests_div:\n",
    "        interests_list.append(interests_div[0])\n",
    "    else:\n",
    "        interests_list.append('')\n",
    "        \n",
    "    profile_url_list.append(member_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a peek (first 5 records) at our Python lists to see if they have the data we wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nick Allen', 'Jonathan Alvarez', 'Greta Backus', 'Steve Baker', 'Mark Bar']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_last_name_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Honda of America Mfg., Inc.',\n",
       " 'Honda of America Mfg., Inc.',\n",
       " 'Honda of America Mfg., Inc.',\n",
       " 'Honda of America Mfg., Inc.',\n",
       " 'Honda of America Mfg., Inc.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Manufacturing Tech Division',\n",
       " 'NA Quality Division',\n",
       " 'NA Quality Division',\n",
       " 'Human Resource ＆ Corp Services',\n",
       " 'NA Quality Division']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "division_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Discrete Simulation', 'MQ INFO', 'MQ Warranty Cost', 'HAM MFG IT', 'MQ INFO']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marysville, OH', 'Raymond, OH', 'Raymond, OH', 'Anna, OH', 'Raymond, OH']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "office_location_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'SQL, VBA, programming, Forecasting, Excel, Excel Macros, Access, data analysis, Sharepoint',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interests_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_url_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic data check: Making sure we have same number of data as the number of BRAIN BRG members in our Python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(first_last_name_list) == members.shape[0]\n",
    "assert len(company_list) == members.shape[0]\n",
    "assert len(division_list) == members.shape[0]\n",
    "assert len(department_list) == members.shape[0]\n",
    "assert len(office_location_list) == members.shape[0]\n",
    "assert len(email_list) == members.shape[0]\n",
    "assert len(skills_list) == members.shape[0]\n",
    "assert len(interests_list) == members.shape[0]\n",
    "assert len(profile_url_list) == members.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more comprehensive data validation, check out great_expectations [library](http://docs.greatexpectations.io/en/latest/core_concepts/expectations.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If our data check passed, then let's go ahead and make a pandas dataframe from our Python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_df = pd.DataFrame({'First_Last_Name': first_last_name_list, 'Company': company_list, \n",
    "                          'Division': division_list, 'Department': department_list,\n",
    "                          'Office_Location': office_location_list, 'Email': email_list,\n",
    "                          'Skills': skills_list, 'Interests': interests_list,\n",
    "                          'Profile_Url': profile_url_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we can save our dataframe as Excel, csv, to a database, email it, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# members_df.to_excel(r'path_to_where_you_want_to_save\\filename.xlxs')\n",
    "# members_df.to_csv(r'path_to_where_you_want_to_save\\filename.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make HTML table from pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, need to create a column containing HTML ```<a>``` tags with ```HREF=``` pointed to their profile page URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHyperlink(row):\n",
    "    \"\"\" Function to convert a string URL to HTML <a> tag \"\"\"\n",
    "    \n",
    "    value = '<a href=\"' + str(row['Profile_Url']) + '\"' + \">Profile Page</>\"\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the function above to create new ```URL_Hyperlink``` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_df['URL_Hyperlink'] = members_df.apply(makeHyperlink, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now display dataframe as HTML table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import HTML\n",
    "\n",
    "HTML(members_df.drop(columns='Profile_Url', axis='columns').to_html(escape=False, index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
