{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classifying Warranty Claims with Symptom Class Names Using Machine Learning</h2><br><br>\n",
    "by Daniel J. Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At Honda Market Quality (MQ), we are responsible for identifying vehicle quality and safety problems.  The primary source of market or field information is warranty claims data.  This data represents the voice of our customers.  The data contains several attributes such as part number, part cost, days to failure, miles to failure, customer's complaint, etc.  Over the years, Honda has accumulated several millions of warranty claims.  In order to efficiently identify market problems, methods have to be employed to \"classify\" or group like or similar claims together so that analysis can be made to efficiently find trends, track problems, and ensure problems are fixed or counter-measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, warranty claims data is classified using several, hard-coded algorithms, requiring extensive maintenance.  The jobs that our IT runs to complete the classification take several hours overnight.  Due to recent advancements and accessibility of [machine learning](https://en.wikipedia.org/wiki/Machine_learning) (ML) methodologies, I believe MQ and our Honda IT professionals should investigate how ML can be used to improve the warranty claims classification process and extend its usage to other applicable areas of business.  Furthermore, I strongly believe MQ need to develop in-house capability and knowledge in machine learning.  Unfortunately at MQ, we do not have associates that are knowledgeable in ML or have limited knowledge, this includes me.  But we can change that and hopefully we can discover benefits of applying machine learning to enhance MQ's business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example is an attempt at a proof-of-concept of how machine learning can be used to classify warranty claims without hard-coded algorithms and is not meant to be representative of a \"production\" application.  The programming language used to employ the machine learning algorithm is Python using the [scikit-learn](http://scikit-learn.org/stable/) machine learning library.  This document is a [Jupyter](http://jupyter.org/) web notebook which allows me to document my process so that perhaps others can duplicate or understand my process as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to confidentiality, raw data will not be available.  Instead source of sample data was from an Excel file which I then \"copy/pasted\" from my computer's \"clipboard\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/pybokeh/Downloads/sample_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation: Data Cleansing and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source data had dollar sign and comma in the part cost amounts.  So we need to remove them and ensure the part cost is a numeric (float) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df['PART_COST_USD'] = df['PART_COST_USD'].str.replace('$','').str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df['PART_COST_USD'] = df['PART_COST_USD'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm data type of the source data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAIL_SHORT_PARTNO        object\n",
       "PART_COST_USD           float64\n",
       "DAYS_TO_FAIL_MINZERO      int64\n",
       "MILES_TO_FAIL             int64\n",
       "TEXT_CLUSTER_FAMILY      object\n",
       "SYMP_CLASS_NM            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the first 5 rows of the training data set we will use.  The features columns that we will use are the first 5 columns and the target or label data will be the last column (\"SYMPTOM_CLASS_NM\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we want to label or classify future claims based on part #, part cost, DTF, MTF, and symptom text cluster family to their appropriate symptom class name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's view our sample data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAIL_SHORT_PARTNO</th>\n",
       "      <th>PART_COST_USD</th>\n",
       "      <th>DAYS_TO_FAIL_MINZERO</th>\n",
       "      <th>MILES_TO_FAIL</th>\n",
       "      <th>TEXT_CLUSTER_FAMILY</th>\n",
       "      <th>SYMP_CLASS_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00030</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOISE/VIBRATION</td>\n",
       "      <td>BRAKE JUDDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01469</td>\n",
       "      <td>458.91</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>FUNCTION ISSUE</td>\n",
       "      <td>BRAKE PEDAL SOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01469</td>\n",
       "      <td>455.32</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>FUNCTION ISSUE</td>\n",
       "      <td>MASTER CYLINDER/BOOSTER/POWER ASSY/FUNCTION ISSUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01611</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>COSMETIC ISSUE</td>\n",
       "      <td>SIDE PANEL / FENDER/FENDER (FRONT)/COSMETIC ISSUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04110</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0</td>\n",
       "      <td>20887</td>\n",
       "      <td>FUNCTION ISSUE</td>\n",
       "      <td>BULBS (INTERIOR)/04110/FUNCTION ISSUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FAIL_SHORT_PARTNO  PART_COST_USD  DAYS_TO_FAIL_MINZERO  MILES_TO_FAIL  \\\n",
       "0             00030           0.00                     0              2   \n",
       "1             01469         458.91                     0             11   \n",
       "2             01469         455.32                     0             10   \n",
       "3             01611           0.00                     0              5   \n",
       "4             04110           2.62                     0          20887   \n",
       "\n",
       "  TEXT_CLUSTER_FAMILY                                      SYMP_CLASS_NM  \n",
       "0     NOISE/VIBRATION                                       BRAKE JUDDER  \n",
       "1      FUNCTION ISSUE                                   BRAKE PEDAL SOFT  \n",
       "2      FUNCTION ISSUE  MASTER CYLINDER/BOOSTER/POWER ASSY/FUNCTION ISSUE  \n",
       "3      COSMETIC ISSUE  SIDE PANEL / FENDER/FENDER (FRONT)/COSMETIC ISSUE  \n",
       "4      FUNCTION ISSUE              BULBS (INTERIOR)/04110/FUNCTION ISSUE  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using machine learning algorithms, most require that the input data do not contain text/string data.  We can use scikit-learn's LabelEncoder() class to convert text/string data to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "part5_encoder = preprocessing.LabelEncoder()\n",
    "text_cluster_encoder = preprocessing.LabelEncoder()\n",
    "symp_class_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "part5_encoder.fit(df.FAIL_SHORT_PARTNO)\n",
    "text_cluster_encoder.fit(df.TEXT_CLUSTER_FAMILY)\n",
    "symp_class_encoder.fit(df.SYMP_CLASS_NM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create new columns containing the integer version of the columns that contain text/string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df['PART5'] = part5_encoder.transform(df.FAIL_SHORT_PARTNO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df['TEXT_CLUSTER'] = text_cluster_encoder.transform(df.TEXT_CLUSTER_FAMILY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df['SYMP_CLASS'] = symp_class_encoder.transform(df.SYMP_CLASS_NM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAIL_SHORT_PARTNO</th>\n",
       "      <th>PART_COST_USD</th>\n",
       "      <th>DAYS_TO_FAIL_MINZERO</th>\n",
       "      <th>MILES_TO_FAIL</th>\n",
       "      <th>TEXT_CLUSTER_FAMILY</th>\n",
       "      <th>SYMP_CLASS_NM</th>\n",
       "      <th>PART5</th>\n",
       "      <th>TEXT_CLUSTER</th>\n",
       "      <th>SYMP_CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00030</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOISE/VIBRATION</td>\n",
       "      <td>BRAKE JUDDER</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01469</td>\n",
       "      <td>458.91</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>FUNCTION ISSUE</td>\n",
       "      <td>BRAKE PEDAL SOFT</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01469</td>\n",
       "      <td>455.32</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>FUNCTION ISSUE</td>\n",
       "      <td>MASTER CYLINDER/BOOSTER/POWER ASSY/FUNCTION ISSUE</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01611</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>COSMETIC ISSUE</td>\n",
       "      <td>SIDE PANEL / FENDER/FENDER (FRONT)/COSMETIC ISSUE</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04110</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0</td>\n",
       "      <td>20887</td>\n",
       "      <td>FUNCTION ISSUE</td>\n",
       "      <td>BULBS (INTERIOR)/04110/FUNCTION ISSUE</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FAIL_SHORT_PARTNO  PART_COST_USD  DAYS_TO_FAIL_MINZERO  MILES_TO_FAIL  \\\n",
       "0             00030           0.00                     0              2   \n",
       "1             01469         458.91                     0             11   \n",
       "2             01469         455.32                     0             10   \n",
       "3             01611           0.00                     0              5   \n",
       "4             04110           2.62                     0          20887   \n",
       "\n",
       "  TEXT_CLUSTER_FAMILY                                      SYMP_CLASS_NM  \\\n",
       "0     NOISE/VIBRATION                                       BRAKE JUDDER   \n",
       "1      FUNCTION ISSUE                                   BRAKE PEDAL SOFT   \n",
       "2      FUNCTION ISSUE  MASTER CYLINDER/BOOSTER/POWER ASSY/FUNCTION ISSUE   \n",
       "3      COSMETIC ISSUE  SIDE PANEL / FENDER/FENDER (FRONT)/COSMETIC ISSUE   \n",
       "4      FUNCTION ISSUE              BULBS (INTERIOR)/04110/FUNCTION ISSUE   \n",
       "\n",
       "   PART5  TEXT_CLUSTER  SYMP_CLASS  \n",
       "0      0             3         161  \n",
       "1      6             1         162  \n",
       "2      6             1        1708  \n",
       "3      7             0        2280  \n",
       "4     11             1         248  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to save the encoders for use later on un-classified data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Data Structure Persistence using Python's pickle library: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Encoders to disk\n",
    "pickle.dump(part5_encoder, open(r'C:\\Users\\pybokeh\\Dropbox\\python\\jupyter_notebooks\\machine_learning\\part5_encoder.sk','wb'))\n",
    "pickle.dump(text_cluster_encoder, open(r'C:\\Users\\pybokeh\\Dropbox\\python\\jupyter_notebooks\\machine_learning\\text_cluster_encoder.sk','wb'))\n",
    "pickle.dump(symp_class_encoder, open(r'C:\\Users\\pybokeh\\Dropbox\\python\\jupyter_notebooks\\machine_learning\\symp_class_encoder.sk','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**-For the sake of simplicity, I resorted to saving the mappings using Python's pickle object serialization library.  In a production environment, it would be more suitable to use a relational database to store the mappings in a table instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are ready to create our features input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our features data will consist of: part5, part cost, DTF, MTF, and symptom text cluster (all represented with numeric values thanks to my mappings made earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "features = df[['PART5','PART_COST_USD','DAYS_TO_FAIL_MINZERO','MILES_TO_FAIL','TEXT_CLUSTER']].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our features data does not contain text/string data.  Let's look at the first 10 rows of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 0.0, 2.0, 3.0],\n",
       " [6.0, 458.91, 0.0, 11.0, 1.0],\n",
       " [6.0, 455.32, 0.0, 10.0, 1.0],\n",
       " [7.0, 0.0, 0.0, 5.0, 0.0],\n",
       " [11.0, 2.62, 0.0, 20887.0, 1.0],\n",
       " [11.0, 4.37, 0.0, 11849.0, 1.0],\n",
       " [12.0, 3.04, 0.0, 3.0, 6.0],\n",
       " [13.0, 0.0, 0.0, 5.0, 4.0],\n",
       " [19.0, 0.0, 0.0, 11.0, 0.0],\n",
       " [19.0, 0.0, 0.0, 14.0, 0.0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of rows in our features data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81403"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create our target/label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "labels = df.SYMP_CLASS.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 10 label data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[161, 162, 1708, 2280, 248, 248, 1247, 2343, 2293, 2293]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of rows in our label data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81403"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning the Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our features training data should contain 80% of our original complete data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65122"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "features_train_std = stdsc.fit_transform(features_train)\n",
    "features_test_std = stdsc.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.86131084,  -0.09973194,   1.05144666,  -0.93794294,\n",
       "          1.81290566],\n",
       "       [  0.9911888 ,  -0.1773592 ,   0.04145509,   1.25145102,\n",
       "         -1.14746417],\n",
       "       [  1.38262607,   0.09687569,  -0.22257824,  -0.31504457,  -0.6540692 ],\n",
       "       [  1.86964685,   0.18940672,   0.7002567 ,   0.28702583,\n",
       "         -1.14746417],\n",
       "       [ -0.38111744,   1.42289478,   1.57438645,   0.45636622,\n",
       "          0.82611572],\n",
       "       [ -1.7261141 ,   0.20117431,   1.86661752,   2.95268154,\n",
       "         -1.14746417],\n",
       "       [ -1.1389582 ,  15.87116858,   0.118358  ,   0.5200144 ,\n",
       "         -0.16067423],\n",
       "       [  0.71809303,  -0.22817634,   0.63617094,   1.45384448,\n",
       "         -1.14746417],\n",
       "       [  1.77633913,  -0.11768862,  -0.49942872,  -0.03554885,\n",
       "         -1.14746417],\n",
       "       [ -1.26640289,  -0.2644505 ,   1.69486768,   0.12311882,\n",
       "          1.81290566],\n",
       "       [ -0.86131084,  -0.13039984,   1.45903209,   0.71212324,  -0.6540692 ],\n",
       "       [ -0.86131084,  -0.09973194,  -0.16618277,  -0.65650672,  -0.6540692 ],\n",
       "       [ -0.35608366,  -0.30918956,   1.08220782,   0.99213643,  -0.6540692 ],\n",
       "       [  1.54420773,  -0.31976374,   0.03120137,  -0.30281947,  -0.6540692 ],\n",
       "       [ -0.86131084,  -0.09973194,   1.18474504,   0.36276975,  -0.6540692 ],\n",
       "       [  1.53738033,  -0.2995035 ,  -0.2277051 ,   0.10500755,  -0.6540692 ],\n",
       "       [ -0.11940066,  -0.32514797,  -0.13029475,  -0.1797275 ,\n",
       "         -1.14746417],\n",
       "       [  1.54420773,  -0.32514797,  -0.28410057,   0.52195489,\n",
       "         -0.16067423],\n",
       "       [ -0.86131084,  -0.100176  ,  -0.18412679,   0.09045385,  -0.6540692 ],\n",
       "       [  1.38262607,   0.09687569,  -0.39432808,  -0.32377679,  -0.6540692 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_std[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model with training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Random Forest classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dc = DecisionTreeClassifier()\n",
    "dc.fit(features_train_std, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting 10 records:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.87268983,  0.85871637, -0.89676043,  0.33204527, -0.6540692 ],\n",
       "       [-1.69197713, -0.22190399, -1.05825654, -0.86045257, -0.6540692 ],\n",
       "       [-0.25594855, -0.31557292, -1.03262224, -0.84680443, -0.6540692 ],\n",
       "       [-0.25594855, -0.27946528, -1.01980509, -0.75372544,  1.81290566],\n",
       "       [-0.86131084, -0.13039984,  1.43083435,  1.21315862, -0.6540692 ],\n",
       "       [-0.86131084, -0.13039984,  0.4644211 , -0.33309116, -0.6540692 ],\n",
       "       [-1.09571804, -0.32514797, -0.03801125, -0.64990904, -0.6540692 ],\n",
       "       [ 0.41313609, -0.32514797,  1.22575992,  0.53547366,  0.33272074],\n",
       "       [ 0.55195977,  0.07350702,  0.94378258,  0.10798298, -0.6540692 ],\n",
       "       [-0.86131084, -0.15043806, -0.96340962, -0.81601527, -0.6540692 ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = features_test_std[:10]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTER/STARTER MOTOR ASSY/FUNCTION ISSUE\n",
      "SEAT BELTS/REAR/FUNCTION ISSUE\n",
      "RELAY/FUSE/RELAY, FUEL PUMP/FUNCTION ISSUE\n",
      "VSA LIGHT ON (PARTS REPLACED)\n",
      "DEAD BATTERY (BATTERY ONLY REPL)\n",
      "DEAD BATTERY (BATTERY ONLY REPL)\n",
      "NOT APPL/1K010/FUNCTION ISSUE\n",
      "TAILGATE / TRUNK/HINGE/NOISE/VIBRATION\n",
      "DOORS (FRONT)/LATCH/FUNCTION ISSUE\n",
      "DEAD BATTERY (BATTERY ONLY REPL)\n"
     ]
    }
   ],
   "source": [
    "for name in symp_class_encoder.inverse_transform(labels_test[:10]):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTER/STARTER MOTOR ASSY/FUNCTION ISSUE\n",
      "SEAT BELTS/REAR/FUNCTION ISSUE\n",
      "RELAY/FUSE/RELAY, FUEL PUMP/FUNCTION ISSUE\n",
      "RELAY/FUSE/RELAY, FUEL PUMP/WARNING LIGHT ON\n",
      "DEAD BATTERY (BATTERY ONLY REPL)\n",
      "DEAD BATTERY (BATTERY ONLY REPL)\n",
      "OTHER/1J816 MOTOR, COOLING FAN/FUNCTION ISSUE\n",
      "TAILGATE / TRUNK/HINGE/NOISE/VIBRATION\n",
      "DOORS (FRONT)/LATCH/FUNCTION ISSUE\n",
      "DEAD BATTERY (BATTERY ONLY REPL)\n"
     ]
    }
   ],
   "source": [
    "for item in test_data:\n",
    "    print(symp_class_encoder.inverse_transform(dc.predict([item]))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the above output to the source data, all but 2 was not classified correctly (80%).  But this was on a sample of 20 data observations.  We can use sklearn's accuracy score for larger data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82999999999999996"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(labels_test[:100], dc.predict(features_test_std[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Using the Machine Learning Model to Classify Future Claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist the model so that we can re-use it without having to retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(clf1, open(r'D:\\jupyter\\machine_learning\\nbayes.sk','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-use the Model and Load Helper Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "clf2 = pickle.load(open(r'D:\\jupyter\\machine_learning\\nbayes.sk','rb'))\n",
    "\n",
    "# Load helper data structures that we made earlier\n",
    "part5_to_int_mapper = pickle.load(open(r'D:\\jupyter\\machine_learning\\part5_to_int_mapper.sk', 'rb'))\n",
    "symptom_to_int_mapper = pickle.load(open(r'D:\\jupyter\\machine_learning\\symptom_to_int_mapper.sk', 'rb'))\n",
    "int_to_symp_class_mapper = pickle.load(open(r'D:\\jupyter\\machine_learning\\int_to_symp_class_mapper.sk', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, in a production environment, it is probably best to load the mappings from a relational database instead of using Python's pickle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a single observation using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEAT BELTS/REAR/COSMETIC ISSUE'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criteria = [part5, part cost, dtf, mtf, symptom]\n",
    "criteria = [part5_to_int_mapper['04823'], 0, 0, 207, symptom_to_int_mapper['COSMETIC ISSUE']]\n",
    "int_to_symp_class_mapper[clf2.predict([criteria])[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That's it!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of symptom class names, we can classify warranty claims with other different types of classification labels so this classification example can be extended for any other classification we can come up with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not tested this model extensively with other larger test data, but so far I have been impressed with the model so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small-scale example shows that a machine learning classification algorithm was able to classify warranty claims without hard-coded algorithms.  It was \"trained\" solely from the training data consisting of just some of the attributes of the warranty claims data."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
