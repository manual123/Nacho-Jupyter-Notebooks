{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with scikit-learn\n",
    "\n",
    "All of the previous machine learning was done manually through function creation without the help of a dedicated machine learning library. In this chapter, we rely upon scikit-learn, one of the most popular and well-developed machine learning libraries available in the Python data science ecosystem. It is easy to use, has an excellent API, and contains most of the common and fundamental machine learning models. \n",
    "\n",
    "## The scikit-learn Estimator\n",
    "\n",
    "scikit-learn uses the term **Estimator** to refer to any object that learns from data. There are several types of estimators that scikit-learn has built for us. Not all estimators are machine learning models, but all of them **learn from data**. Here are the main types of estimators:\n",
    "\n",
    "* Regressors - Supervised learning with continuous target\n",
    "* Classifiers - Supervised learning with categorical target\n",
    "* Clusterers - Unsupervised learning\n",
    "* Transformers - Transform the input/output data\n",
    "* Meta-estimators - Learn from other estimators\n",
    "\n",
    "### Understanding the scikit-learn API\n",
    "\n",
    "It is instructive to take a glimpse of the scikit-learn API before using it. I like to analogize the API to a house where each of the rooms contains the useful objects for machine learning. Take a look at the scikit-learn 'house' below. It shows some of the most popular objects in scikit-learn, but is nowhere near a complete list. In order to view all of the objects available within scikit-learn, [visit the official documentation's API page][0].\n",
    "\n",
    "![][1]\n",
    "\n",
    "### House, Room, Object <-> Library, Module, Estimators and Helper Functions\n",
    "\n",
    "In this analogy, the house is the scikit-learn library, each room is a module, and the objects in the room are either estimators or helper functions. All estimators are Python types written using **CamelCase** where the first letter of each word is capitalized.\n",
    "\n",
    "Nearly every other object in scikit-learn is a **helper function**. The helper functions perform a single task and are written using **snake_case** where all letters are lowercase and the words are separated with an underscore.\n",
    "\n",
    "[0]: https://scikit-learn.org/stable/modules/classes.html\n",
    "[1]: images/scikit_house.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The three-step process for each estimator - Import, Instantiate, Fit\n",
    "\n",
    "A simple three-step process exists to use any estimator in scikit-learn. This standardized process makes scikit-learn one of the easier libraries to learn and use. Here are the three steps:\n",
    "\n",
    "1. **Import** the estimator from its module\n",
    "2. **Instantiate** the estimator\n",
    "3. **Fit** the estimator with data\n",
    "\n",
    "### Preparing data for scikit-learn estimators\n",
    "\n",
    "scikit-learn has certain requirements on the data before it can be used by the estimator.\n",
    "\n",
    "* Missing values are not allowed. They must be filled or dropped\n",
    "* Input data must be numeric (either integer or float).\n",
    "* All string data must be encoded as numeric.\n",
    "* The target variable must be numeric for regression. \n",
    "* The target variable may be either numeric or string for classification.\n",
    "* Input data must be two-dimensional\n",
    "* The target variable may be one-dimensional\n",
    "\n",
    "Let's begin by reading in the housing sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "housing = pd.read_csv('../data/housing_sample.csv')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign data to `X` and `y`\n",
    "\n",
    "We need to select which features to use as input data for our model. We'll use just a single feature, `GrLivArea` as the input and `SalePrice` as the target. The scikit-learn documentation uses the capital letter `X` as the variable name for the input data and lowercase `y` for the target. We also adhere to these conventions. The first five values of the input and output variables are displayed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing[['GrLivArea']]\n",
    "y = housing['SalePrice']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is a DataFrame used for the input?\n",
    "\n",
    "Machine learning models in scikit-learn expect the input data to always be two dimensional and will error if given one-dimensional data. These models allow the output data to be one-dimensional. A DataFrame is always two dimensions even if it contains just a single column. On the other hand, pandas Series are always one-dimensional. Let's verify the number of dimensions with the `ndim` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import the Estimator\n",
    "\n",
    "The scikit-learn library is built such that all the estimators are defined in specific modules. By convention, we will import just the single estimator class from its respective module into our namespace. Let's import the `LinearRegression` estimator from the `linear_model` module. Using the house analogy, \"We go into the scikit-learn house, enter the linear_model room, and take the LinearRegression object\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Instantiate the Estimator\n",
    "\n",
    "Just like any other Python class, a single instance of it must be created in order for us to use it. This is called **instantiation** or **construction**. Let's instantiate the `LinearRegression` estimator to create a single instance. I like to use the first letters of the words in each estimator's name as the variable name. In this case it is `lr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Fit the estimator with data\n",
    "\n",
    "We now have a single linear regression instance that is ready to learn from data. For it to learn from data, we must pass it both input and output data to its `fit` method. After calling the `fit` method, the model is trained and has finished learning from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returned value, but no assignment statement\n",
    "\n",
    "Notice how there is an 'Out' section of the cell above. The `fit` method just returned something and we didn't assign this value to a new variable name. All scikit-learn estimators are trained in-place and return themselves. There is no need to make an assignment as `lr` itself has been modified to contain the results of the training.\n",
    "\n",
    "### Accessing the model\n",
    "\n",
    "A trained linear regression model is one who's coefficients minimize the sum of squared error (or equivalently maximize $R^2$). After training, scikit-learn stores the intercept ($w_{0}$) in the `intercept_` attribute and the slope ($w_{1}$) in the `coef_` attribute. Let's look at these now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final model\n",
    "\n",
    "Our model can now be written as the following, where $x_{1}$ is the square footage of the house and $\\hat{y}$ is the predicted sale price.\n",
    "\n",
    "$$\\hat{y} = 18569 + 107x_{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens during `fit`?\n",
    "\n",
    "Even though the `fit` method seemed to execute instantaneously, it has done a lot of work for us. The `fit` method uses an algorithm to learn the coefficients that minimize the squared error. \n",
    "\n",
    "### How does the `fit` method minimize the squared error?\n",
    "\n",
    "There have been a number of methods developed that minimize the sum of squared error for linear regression models. We even made an attempt with a simple iterative process. We searched many combinations of the model parameters to find the combination that produced a relatively low sum of squared error. Although this method did produce a reasonable fitted line to the data, it isn't going to produce the combination of coefficients that minimize the SSE. \n",
    "\n",
    "scikit-learn does something much more intelligent and complex with a method called the [singular value decomposition (SVD)][1]. This method has been proven to return the combination of coefficients that minimize the SSE.\n",
    "\n",
    "Other methods besides SVD exist that can find the coefficients that minimize SSE. The **normal equations** and **gradient descent** are other valid methods.\n",
    "\n",
    "### Ordinary Least Squares\n",
    "\n",
    "This entire process of minimizing the sum of squared error is also referred to as [ordinary least squares][2]. \n",
    "\n",
    "### Simple linear regression model interpretation\n",
    "\n",
    "One of the strengths of linear regression is that interpreting its results is easier than most other models. For example, let's take our simple linear regression involving just `GrLivArea` given by the equation above.\n",
    "\n",
    "Mathematically, for every one unit increase in above ground square footage, a corresponding 107 dollar increase in sale price is predicted. The intercept (18,569) translates to the price of a 0 square foot home, but since no house in the dataset had a square footage anywhere neat 0, it isn't quite meaningful here.\n",
    "\n",
    "[1]: https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares-complexity\n",
    "[2]: https://en.wikipedia.org/wiki/Ordinary_least_squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<span  style=\"color:green; font-size:16px\">Use the three-step process to build a simple linear regression model using other columns as the feature. Write a for loop to iterate through all of the numeric columns printing out the y-intercept and slope of the model. Can you also make a scatter plot and plot the regression line through the cloud of points?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
