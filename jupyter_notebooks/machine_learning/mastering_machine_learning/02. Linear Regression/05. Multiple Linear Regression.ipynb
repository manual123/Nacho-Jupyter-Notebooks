{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "Previously, we used a single feature to predict the sale price of a house. Any number of features may be used with linear regression to build a model. **Multiple Linear Regression** refers to linear regression with two or more features. Let's see the general form of the model.\n",
    "\n",
    "$$\\hat{y} = w_{0} + w_{1}x_{1} + w_{2}x_{2} + ... + w_{p}x_{p}$$\n",
    "\n",
    "Where `p` is the number of predictor variables (features). The above equation is no longer an equation for a line but for a [hyperplane][1].\n",
    "\n",
    "## Same Goal - minimize squared error\n",
    "\n",
    "Multiple linear regression has the same goal as simple linear regression - to choose coefficients that minimize the sum of squared errors.\n",
    "\n",
    "### Naive Iterative process no longer feasible\n",
    "\n",
    "Our naive iterative process that we employed to search for the optimal coefficients is not quite a feasible solution as the number of combinations grows exponentially with each added feature. On the other hand, the method employed by scikit-learn learns the values of coefficients efficiently.\n",
    "\n",
    "## Choose features to build a model\n",
    "\n",
    "Let's read in the housing dataset and select `GarageArea` and `FullBath` in addition to `GrLivArea` as features in the model.\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Hyperplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "housing = pd.read_csv('../data/housing_sample.csv')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input data now consists of three features. Let's select it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing[['GrLivArea', 'GarageArea', 'FullBath']]\n",
    "y = housing['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import, Instantiate, Fit\n",
    "\n",
    "Let's use the same three-step process to build a model from these three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the coefficients of the model\n",
    "\n",
    "To see the trained coefficients of the model, access the `intercept_` and `coef_` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formally write the model\n",
    "\n",
    "We can formally write out the mathematical definition of our model as the following, where $x_{1}$, $x_{2}$, and $x_{3}$ represent our features.\n",
    "\n",
    "$$\\hat{y} = -15836 + 70x_{1} + 132x_{2} + 17942x_{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "It is uncommon to create your own input data for predictions. Instead, you are more likely to have new observed data absent of a predicted value that you would use your model with. For instance, when a new house comes on the market, you can use your model to determine what it could sell at.\n",
    "\n",
    "### Using our training data to make predictions\n",
    "\n",
    "Instead of creating our own data by hand, we can select rows of our training data to use as input data for prediction. Let's select the first 10 rows of our input data to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(X.head(10)).round(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare it to the actual sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot predicted vs actual values\n",
    "It might be helpful to plot the predicted and actual values on the same plot. We do so below for the first 10 observations. A few predictions are very close to the actual observed sale price. The x-axis corresponds to the observation number (1, 2, 3, etc...). The sale price is plotted on the y-axis. For each observation, two points are plotted, one for the predicted and one for the actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X.head(10)).round(-3)\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.scatter(np.arange(10), y_pred, label='predicted')\n",
    "ax.scatter(np.arange(10), y.head(10), label='actual')\n",
    "ax.legend()\n",
    "ax.set_title('Actual vs Predicted for first 10 rows')\n",
    "ax.set_ylabel('Sale Price')\n",
    "ax.set_xticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model performance\n",
    "We can use the `score` method again to determine what the $R^2$ of our model is, but we need to remember that this is calculated on data that the model has already seen and will not be an accurate measure of how the model will perform in the future on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing multivariate and univariate model\n",
    "\n",
    "Let's compare the performance of our new multivariate model to the univariate model that just uses `GrLivArea`. We don't have to import the linear regression model again, just begin by instantiating a new model and calculating $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LinearRegression()\n",
    "X2 = housing[['GrLivArea']]\n",
    "lr2.fit(X2, y)\n",
    "lr2.score(X2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new model explains about 12% more of the inherent variance in the data suggesting that there is value in using the variables garage area and full baths. Though, this is a tentative conclusion as we are still evaluating on the training set and not on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression model interpretation\n",
    "\n",
    "Interpretation of the linear regression model when using multiple features is more complex than the univariate case. From our model above, every one-unit increase in `GrLivArea` translates to an increase of 70 dollars in sale price assuming the other features are held constant. \n",
    "\n",
    "For instance, if a particular house has 1,000 square feet of living area, 500 square feet of garage area and two full baths, then increasing the living area to 1,001 square feet while keeping garage area and number of full baths the same will lead to a 70 dollar increase in the sale price.\n",
    "\n",
    "A major issue with this interpretation is that many features are correlated with one another, meaning that increasing the value of one likely leads to a change in another. Theoretically, in order for us to use the interpretation above, the features must be uncorrelated with one another. \n",
    "\n",
    "With our particular data, this isn't the case. Using the DataFrame `corr` method, we see that above ground living area and garage area have a correlation of nearly .5 so increasing one will likely lead to an increase in the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.corr().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions are still viable\n",
    "\n",
    "There are many assumptions that are made by linear regression. Features are assumed to be uncorrelated with one another. This assumption is commonly broken. Read more about assumptions and model interpretation [here][1]. Even when model assumptions are broken, the model can still make good predictions. \n",
    "\n",
    "### No statistical output with scikit-learn\n",
    "\n",
    "Scikit-learn does not produce advanced statistical output and metrics commonly found in statistics textbooks. If you desire more formal statistical output, use the [statsmodels][2] library.\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Linear_regression#Assumptions\n",
    "[2]: https://www.statsmodels.org/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "<span  style=\"color:green; font-size:16px\">Build several models with more than one feature. Track the $R^2$ of each model you build. Which combination of features produces the highest $R^2$.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
