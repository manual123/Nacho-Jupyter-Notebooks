{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Data\n",
    "\n",
    "All of the features examined thus far have been numeric. There are other features in the dataset that have string values. We ignored these at the time, because all data passed to a scikit-learn estimator must be numeric. Let's select some string and numeric columns as our input data and attempt to fit a machine learning model with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "housing = pd.read_csv('../data/housing_sample.csv')\n",
    "X = housing[['Neighborhood', 'Exterior1st', 'GrLivArea', 'GarageArea', 'HeatingQC']]\n",
    "y = housing['SalePrice']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to fit the model\n",
    "\n",
    "scikit-learn machine learning estimators only work with numeric data, so the following raises an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "If we wish to use string columns in our dataset, we will need to **encode** them as numeric in some fashion. As with missing value imputation, there are different encoding strategies available. \n",
    "\n",
    "Columns containing categorical (discrete) values can be divided into two types - **ordinal** and **nominal**. Ordinal categorical columns are those where the column values have some inherent **order**. For example, restaurant ratings ('Very good', 'good', 'average', etc...). Nominal categorical columns are those where there is no inherent ordering of the column values. Neighborhood and house exterior from the housing dataset are examples of those.\n",
    "\n",
    "### Numeric columns may be categorical\n",
    "\n",
    "Categorical data is not limited to just strings. Numeric columns can represent categories such as zip code, room number, or stage of disease such as cancer.\n",
    "\n",
    "### One-hot encoding\n",
    "\n",
    "One-hot encoding is a strategy that may be used primarily for nominal categorical columns (but can be used for ordinal columns as well). It works by first finding the number of unique values in a column. It then creates a new array with the number of columns equal to the number of unique values. Each column represents one of the unique values. The number of rows stays the same. Each row of the new array is composed entirely of 0's except for the column corresponding to the original value, which will be encoded as 1.\n",
    "\n",
    "### Easy to see with pandas\n",
    "\n",
    "One-hot encoding is more easily explained with a simple example using pandas. The `get_dummies` function performs one-hot encoding and use it on the `Exterior1st` column. Let's begin by outputting the first few values to verify the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['Exterior1st'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now complete the one-hot encoding with the `get_dummies` function and highlight where the 1 is located in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(housing['Exterior1st']).head().style.highlight_max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding in scikit-learn\n",
    "\n",
    "One-hot encoding is accomplished with the `OneHotEncoder` transformer of the `preprocessing` module. By default, it returns a sparse array which is a special object from the scipy library that saves memory for datasets that have only a few unique values. We'll set the `sparse` parameter to `False` so that we get back a normal numpy array allowing us to see the actual values. Let's complete the three-step process and assign the encoded array to a separate variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "X_encode = ohe.fit_transform(X)\n",
    "X_encode[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite difficult to interpret. Let's get the shape of the returned array to help understand what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encode.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's a lot of features - what happened?\n",
    "\n",
    "We wanted to encode just the string columns. By default, `OneHotEncoder` encodes each column of data regardless of its type. It treats every unique value as a category to be encoded. Let's verify that there are a total of 1347 unique values. We can get the number of unique values in each column with the `nunique` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing all the values in this Series verifies that we do indeed have a total of 1347 combined unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.nunique().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only use the string columns\n",
    "\n",
    "Instead of transforming all four columns, we can transform just the string columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encode2 = ohe.fit_transform(X[['Neighborhood', 'Exterior1st', 'HeatingQC']])\n",
    "X_encode2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, there are 45 total unique values between the three columns, so we expect the number of columns in the returned array to be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encode2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the feature names\n",
    "\n",
    "scikit-learn returns a numpy array which is devoid of column names. It's not easily possible to decipher what categories each new column reference. The `get_feature_names` method returns the feature names allowing us to know the exact encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how feature name begins with 'x0', 'x1', or 'x2'. This references the original column. The first column, `x0_Blmgtn` equals 1 whenever the `Neighborhood` value is 'Blmgtn'. The column, `x1_WdShing` is 1 whenever the `Exeterior1st` column is 'WdShing', and the column `x2_Fa` is 1 whenever `HeatingQC` is 'Fa'. The unique values for each feature may be accessed with the `categories_` attribute. Below, a list of three arrays is returned, one for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values that only appear in the test set\n",
    "\n",
    "If a value appears in the test set that was not present during training, you will get an error when attempting to encode it. Let's see this with a simple example using the following array containing vehicle makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array([['Toyota'], ['Kia'], ['Ford'], ['Ford'], ['Kia'], ['Kia']])\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate a new `OneHotEncoder` and transform this single column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe2 = OneHotEncoder(sparse=False)\n",
    "ohe2.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only three unique values in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe2.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If new data arrives that needs to be transformed using the same mapping, it is only possible if it contains categories found in the training set. The following array doesn't introduce any new values, so the transformation happens without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_new = np.array([['Kia'], ['Kia'], ['Toyota']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the `transform` method to use the same encoding that was learned during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe2.transform(X1_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If new data arrives that contains a category not present during training, an error will be raised by default. Here, the value 'Honda' is new and responsible for the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_new2 = np.array([['Kia'], ['Kia'], ['Honda']])\n",
    "ohe2.transform(X1_new2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling values unseen during training\n",
    "\n",
    "The `OneHotEncoder` provides two ways to handle values that are unseen during training, but that appear later. The first involves the use of the `categories` parameter. If the distinct universe of values for the feature is known, you can create create a list of these categories and pass it to `categories`. \n",
    "\n",
    "You need to use a list of lists, where each column is given its own list of categories. Here, we only have a single column we are transforming, so there is only one inner list. Each list of categories must be sorted in alphabetical order. Here, we instantiate a new `OneHotEncoder` passing it a list of five categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [['Ford', 'Honda','Kia', 'Tesla', 'Toyota']]\n",
    "ohe3 = OneHotEncoder(categories=categories, sparse=False)\n",
    "ohe3.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming this yields a similar mapping as before, but with two columns of all zeros for 'Honda' an 'Tesla'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe3.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the one-hot encoder can transform the array `X1_new2` which contains 'Honda' as its last value. Let's output the array again before transforming it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_new2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe3.transform(X1_new2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way to handle values unseen during training is to set the `handle_unknown` parameter to 'ignore'. By default, this value is 'error'. Let's re-instantiate the model one more time and fit and transform the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe4 = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "ohe4.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that `handle_unknown` has been set to 'ignore', no error will be raised when an unknown value is encountered during transformation of a future dataset. Instead, the entire row will be composed of 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe4.transform(X1_new2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverting the encoding\n",
    "\n",
    "The `inverse_transform` method is available to take an array of the one-hot encoded values and return the original data. Let's output the original array of data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we encode the data and assign the result to the variable name 'X1_transformed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_transformed = ohe2.transform(X1)\n",
    "X1_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `inverse_transform` method returns the original input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe2.inverse_transform(X1_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Encoding\n",
    "\n",
    "One-hot encoding is a standard encoding procedure for nominal categorical variables, those that have no inherent ordering, such as `Neighborhood` and `Exterior1st`. But, the feature `HeatingQC` does have a clear ordering, so we have an option to encode it differently. Ordinal encoding returns just a single column encoding each value with an integer. The lowest category becomes 0 and the highest `n - 1` where `n` is the number of unique categories.\n",
    "\n",
    "scikit-learn provides the `OrdinalEncoder` transformer to make this transformation. By default, it will use the alphabetic ordering as the natural inherent order. This isn't likely to be the case for most ordinal features. Instead, you need to supply the first parameter, `categories`, with the exact order as a list. \n",
    "\n",
    "Let's begin our three-step process by importing the `OrdinalEncoder` and instantiating it with the correct order of categories. Each feature requires its own list of ordered categories, even if it has the same categories in the same order. Therefore, scikit-learn requires that you give it a list of lists, where each inner list corresponds to each feature being transformed. In our example, we are only transforming a single column, therefore, we only have one inner list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "order = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]\n",
    "oe = OrdinalEncoder(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now setup to transform `HeatingQC`, our ordinal feature containing string data. We need to pass the `fit_transform` method a two-dimensional array. The first five values are output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_heating_transformed = oe.fit_transform(X[['HeatingQC']])\n",
    "X_heating_transformed[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the encoding happened correctly. The lowest category 'Po' corresponds to 0 and the highest category, 'Ex' corresponds to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['HeatingQC'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the `OneHotEncoder`, the categories are stored in the `categories_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning with categorical data\n",
    "\n",
    "Once we have applied an encoding strategy to categorical data, we can use scikit-learn machine learning estimators to build models that learn from it. Let's build a model from our two nominal categorical features, `Neighborhood` and `Exterior1st`. We begin by selecting these features as their own DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nom = housing[['Neighborhood', 'Exterior1st']]\n",
    "X_nom.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now learn the categories and transform the strings using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "X_nom_t = ohe.fit_transform(X_nom)\n",
    "X_nom_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take this array of transformed data an pass it to any of the regression estimators. Here, we choose to model the data using k-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knr = KNeighborsRegressor(n_neighbors=5)\n",
    "knr.fit(X_nom_t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr.predict(X_nom_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using features with different transformations\n",
    "\n",
    "Simultaneously using continuous, nominal, and ordinal features in our model requires the use of the `ColumnTransformer`, subject of the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<span  style=\"color:green; font-size:16px\">Find the cross-validated mean score using linear regression with `HeatingQC` encoded as ordinal. Repeat this using, but use one-hot encoding. Which encoding produces a better result?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
