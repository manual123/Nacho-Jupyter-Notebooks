{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types and Missing Values\n",
    "\n",
    "One of the most important pieces of information you can have about your DataFrame is the data type of each column. pandas stores its data such that each column is exactly one data type. A large number of data types are available for pandas DataFrame columns. This chapter focuses only on the most common data types and provides a brief summary of each one. For extensive coverage of each and every data type, see the chapter **Changing Data Types** in the **Essential Commands** part.\n",
    "\n",
    "## Common data types\n",
    "\n",
    "The following are the most common data types that appear frequently in DataFrames. \n",
    "\n",
    "* **boolean** - Only two possible values, `True` and `False`\n",
    "* **integer** - Whole numbers without decimals\n",
    "* **float** - Numbers with decimals\n",
    "* **object** - Typically strings, but may contain any object\n",
    "* **datetime** - Specific date and time with nanosecond precision\n",
    "\n",
    "### More on the object data type\n",
    "\n",
    "The object data type is the most confusing and deserves a longer discussion. Each value in an object column can be *any* Python object. Object columns can contain integers, floats, or even data structures such as lists or dictionaries. Anything can be contained in object columns.  But, nearly all of the time, columns of the object data type only contain **strings**. When you see that a column is an object data type, you should expect the values to be strings. Unfortunately, pandas does not provide its users with a specific data type for strings. If you do have strings in your columns, the data type will be object.\n",
    "\n",
    "### The importance of knowing the data type\n",
    "\n",
    "Knowing the data type of each column of your pandas DataFrame is very important. The main reason for this is that every value in each column will be of the same type. For instance, if you select a single value from a column that has an integer data type, then you are guaranteed that this value is also an integer.  Knowing the data type of a column is one of the most fundamental pieces of knowledge of your DataFrame.\n",
    "\n",
    "### A major exception with the object data type\n",
    "\n",
    "The object data type, is unfortunately, an exception to the information in the previous section. Although columns that have object data type are typically strings, there is no guarantee that each value will be a string. You could very well have an integer, list, or even another DataFrame as a value in the same object column.\n",
    "\n",
    "## Missing Value Representation\n",
    "\n",
    "### `NaN`,  `None`, and `NaT`\n",
    "\n",
    "pandas represents missing values differently based on the data type of the column.\n",
    "\n",
    "* `NaN` - Stands for not a number and is a float data type\n",
    "* `None` - The literal Python object `None` and only found in object columns\n",
    "* `NaT` - Stands for not a time and is used for missing values in datetime columns\n",
    "\n",
    "### Missing values for each data type\n",
    "\n",
    "* **boolean and integer** - No representation for missing values exist for boolean and integer columns. This is an unfortunate limitation.\n",
    "* **float** -  Uses `NaN` as the missing value.\n",
    "* **datetime** - Only uses `NaT` as the missing value.\n",
    "* **object** - Can contain any Python object so all three of the missing value representations may appear in these columns, but typically you will encounter `NaN` or `None`.\n",
    "\n",
    "### Missing values in boolean and integer columns\n",
    "\n",
    "Knowing that a column is either a boolean or integer column guarantees that there are no missing values in that column as pandas does not allow for it. If, for instance, you would like to place a missing value in a boolean or integer column, then pandas converts the entire column to float. This is because a float column can accommodate missing values. When booleans are converted to floats, `False` becomes 0 and `True` becomes 1.\n",
    "\n",
    "### Integer NaN update for pandas 0.24\n",
    "\n",
    "With the release of pandas version 0.24 (February 2019), missing value representation was made possible for a special kind of integer data type called **Int64Dtype**. There is still no missing value representation for the default integer data type. \n",
    "\n",
    "## Finding the data type of each column\n",
    "\n",
    "The `dtypes` DataFrame attribute (NOT a method) returns the data type of each column and is one of the first commands you should execute after reading in your data. Let's begin by using the `read_csv` function to read in the bikes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bikes = pd.read_csv('../data/bikes.csv')\n",
    "bikes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the data types of each column in our `bikes` DataFrame. The returned object is a Series with the data types as the values and the column names as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do `starttime` and `stoptime` have object as the data type?\n",
    "\n",
    "From the visual display of the bikes DataFrame above, it appears that both the `starttime` and `stoptime` columns are datetimes. The result of the `dtypes` attribute shows that they are objects (strings).\n",
    "\n",
    "The `read_csv` function requires that you provide a list of columns that are datetimes to the `parse_dates` parameter, otherwise it will read them in as strings. Let's reread the data using the `parse_dates` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = pd.read_csv('../data/bikes.csv', parse_dates=['starttime', 'stoptime'])\n",
    "bikes.dtypes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are all those 64's at the end of the data types?\n",
    "\n",
    "Booleans, integers, floats, and datetimes all use a particular amount of memory for each of their values. The memory is measured in **bits**. The number of bits used for each value is the number appended to the end of the data type name. For instance, integers can be either 8, 16, 32, or 64 bits while floats can be 16, 32, 64, or 128. A 128-bit float column will show up as `float128`. \n",
    "\n",
    "Technically a `float128` is a different data type than a `float64` but generally you will not have to worry about such a distinction as the operations between different float columns will be the same. \n",
    "\n",
    "**Booleans** are always stored as 8-bits. There is no set bit size for values in an **object** column as each value can be of any size.\n",
    "\n",
    "## Getting more metadata\n",
    "\n",
    "**Metadata** can be defined as data on the data. The data type of each column is an example of metadata. The number of rows and columns is another piece of metadata. We find this with the `shape` attribute, which returns a tuple of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of values with the `size` attribute\n",
    "The `size` attribute returns the total number of values (the number of columns multiplied by the number of rows) in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data types plus more with the `info` method\n",
    "The `info` DataFrame method provides output similar to `dtypes`, but also shows the number of non-missing values in each column along with more info such as:  \n",
    "\n",
    "* Type of object (always a DataFrame)\n",
    "* The type of index and number of rows\n",
    "* The number of columns\n",
    "* The data types of each column and the number of non-missing (a.k.a non-null)\n",
    "* The frequency count of all data types\n",
    "* The total memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data types\n",
    "\n",
    "There are several more data types available in pandas. An extensive and formal discussion on all data types is available in the chapter **Changing Data Types** from the **Essential Commands** part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Use the `bikes` DataFrame for the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">What type of object is returned from the `dtypes` attribute?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">What type of object is returned from the `shape` attribute?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span style=\"color:green; font-size:16px\">What type of object is returned from the `info` method?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "<span  style=\"color:green; font-size:16px\">The memory usage from the `info` method isn't correct when you have objects in your DataFrame. Read the docstrings from it and get the true memory usage.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
