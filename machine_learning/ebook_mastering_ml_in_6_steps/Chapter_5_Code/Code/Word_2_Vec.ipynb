{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "\n",
    "Tomas Mikolov led team at Google created Word2Vec (word to vector) in 2013. It utilizes two models. \n",
    "\n",
    "* Continuous bag-of-words (CBOW) model to predict the current word from a window of surrounding context words or given a set of context words predict the missing word that is likely to appear in that context. For example \"cigarette smoking is ??? to health\" will likely predict the missing word as injurious based on the training set.\n",
    "\n",
    "* Continuous skip-gram model to predict the surrounding window of context words using the current word or given a single word, predict the probability of other words that are likely to appear near it in that context. For example, \n",
    "\n",
    "\n",
    "I'll use Google's pre-trained model which you can download from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit, this model includes vocabulary of 3 million words/phrases taken from 100 billion words from a Google News dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.Word2Vec.load_word2vec_format('Data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'queen', 0.7118192911148071),\n",
       " (u'monarch', 0.6189674139022827),\n",
       " (u'princess', 0.5902431607246399),\n",
       " (u'crown_prince', 0.5499460697174072),\n",
       " (u'prince', 0.5377321243286133)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'mother', 0.831214427947998),\n",
       " (u'daughter', 0.8000643253326416),\n",
       " (u'husband', 0.769158124923706)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['girl', 'father'], ['boy'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training word2vec model on your own custom data\n",
    "\n",
    "Parameters\n",
    "* size: The dimensionality of the vectors, note that bigger size values require more training data, but can lead to more accurate models\n",
    "* window: The maximum distance between the current and predicted word within a sentence\n",
    "* min_count: Ignore all words with total frequency lower than this\n",
    "* sg = 0 for CBOW model and 1 for skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('injurious', 0.16143128275871277)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [['cigarette','smoking','is','injurious', 'to', 'health'],['cigarette','smoking','causes','cancer'],['cigarette','are','not','to','be','sold','to','kids']]\n",
    "\n",
    "# train word2vec on the two sentences\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1, sg=1, window = 3)\n",
    "\n",
    "model.most_similar(positive=['cigarette', 'smoking'], negative=['kids'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
