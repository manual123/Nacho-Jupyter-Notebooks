{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep NLP\n",
    "\n",
    "Technique such as topic modeling is generally known as shallow NLP where you try to extract knowledge from text through semantic or syntactic analysis approach i.e., try to form groups by retaining words that are similar, and holds higher weight in a sentence/document. Shallow NLP is less noise than the n-grams; however the key drawback is that it does not specify the role of items in the sentence. In contrast DNLP focuses on semantic approach i.e., it detects relationships within the sentences, and further it can be represented or expressed as complex construction of the form such as subject:predicate:object (known as triples or triplets) out of syntactically parsed sentences to retain the context. Sentences are made up of any combination of actor, action, object and named entities (person, organizations, locations, dates etc). For example, consider the sentence \"the flat tire was replaced by the driver\". Here driver is the subject (actor), replaced is the predicate (action) and flat tire is the object (action). So the triples for would be driver:replaced:tire, which captures the context of the sentence. Note that triples are one of the forms widely used and you can form similar complex structure based on the domain or problem at hand. \n",
    "\n",
    "Additional Info: http://www.mswamynathan.com/2017/01/21/triplets-for-concept-extraction-from-english-sentence-deep-nlp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from chunker import PennTreebackChunker\n",
    "from extractor import SOPExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunker = PennTreebackChunker()\n",
    "extractor = SOPExtractor(chunker)\n",
    "\n",
    "def extract(sentence):  \n",
    "    sentence = sentence if sentence[-1] == '.' else sentence+'.'\n",
    "    global extractor\n",
    "    sop_triplet = extractor.extract(sentence)\n",
    "    return sop_triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fox:jumps:dog\n",
      "squirrel:become:visitor\n",
      "driver:change:tire\n",
      "driver:crashed:bumper\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "  'The quick brown fox jumps over the lazy dog.',\n",
    "  'A rare black squirrel has become a regular visitor to a suburban garden',\n",
    "  'The driver did not change the flat tire',\n",
    "  \"The driver crashed the bike white bumper\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    sop_triplet = extract(sentence)\n",
    "    print sop_triplet.subject + ':' + sop_triplet.predicate + ':' + sop_triplet.object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
