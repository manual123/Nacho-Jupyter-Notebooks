{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What it means to be a linear model\n",
    "\n",
    "In this chapter, we will explore what the word **linear** actually means with regards to a linear model such as linear regression. Surprisingly, linear models can model non-linear data.\n",
    "\n",
    "### What exactly does \"linear\" mean?\n",
    "\n",
    "For a model to be linear, it must be a linear combination of the coefficients. This means that the input data (i.e. $x_{1}$, $x_{2}$, etc...) may be arbitrarily transformed but not the coefficients (i.e. $w_{0}$, $w_{1}$, etc...).\n",
    "\n",
    "A nice [blog post from minitab][1] words it as:\n",
    "\n",
    "> A model is linear when each term is either a coefficient or the product of a coefficient and a feature. A linear equation is constructed by adding the results for each term. This constrains the equation to just one basic form:\n",
    "\n",
    "$$Response = coefficient + coefficient * feature + ... + coefficient * feature$$\n",
    "\n",
    "This means that our model for multiple linear regression is linear.\n",
    "\n",
    "$$y = w_{0} + w_{1}x_{1} + w_{2}x_{2} + ... + w_{p}x_{p}$$ \n",
    "\n",
    "Also linear, is a model that transforms the input data in any way such as $$y = w_{0} + w_{1}x_{1} + w_{2}x_{1}^2 + w_{2}cos(x_{1}) + w_{3}e^{x_{2}^2}$$\n",
    "\n",
    "### What isn't linear?\n",
    "\n",
    "Any equation that does not add together $coefficient * feature$ terms would not be linear. For instance, if we had a coefficient as an exponent such as this: \n",
    "\n",
    "$$y = x_{1}^{w_{1}}$$\n",
    "\n",
    "Another example:\n",
    "\n",
    "$$y = e^{w_{1}}x_{1} $$\n",
    "\n",
    "## Linear regression is more flexible than a straight line\n",
    "\n",
    "Because of the ability to transform the input data, linear regression is more flexible than it first appears. It is able to fit highly non-linear data.\n",
    "\n",
    "### Trivial example of modeling a non-linear function\n",
    "\n",
    "Let's plot some data with a known functional relationship given by the equation:\n",
    "\n",
    "$$y = 8 - 12x + 5x^{2} + 2x^{3}$$\n",
    "\n",
    "[1]: http://blog.minitab.com/blog/adventures-in-statistics-2/what-is-the-difference-between-linear-and-nonlinear-equations-in-regression-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(-5, 5, .2)\n",
    "y = 8 - 12 * x + 5 * x ** 2 + 2 * x ** 3\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.scatter(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use linear regression to model this non-linear function\n",
    "\n",
    "Let's attempt to model this function with a linear regression model involving one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x.reshape(-1, 1)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.scatter(x, y)\n",
    "ax.plot(x, y_pred, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a single feature in our model, linear regression was not able to learn the correct model. Instead, we can add new features for the squared and cubed terms so that our model becomes:\n",
    "\n",
    "$$\\hat{y} = w_{0} + w_{1}x + w_{2}x^2 + w_{3}x^3$$\n",
    "\n",
    "To formalize the definition into a linear regression, we can rewrite the equation allowing $x_{2} = x^2$ and $x_{3} = x^3$ so that it becomes:\n",
    "\n",
    "$$\\hat{y} = w_{0} + w_{1}x + w_{2}x_{2} + w_{3}x_{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create new input data\n",
    "\n",
    "We have to create new input data by adding two new columns, one for each new term. We square and cube the original data and add them as the new columns. The first 10 rows of the new input data are outputted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack((x, x ** 2, x ** 3))\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn a perfect fit\n",
    "Linear regression can now learn a perfect fit to the data with zero error and recover the coefficients exactly. Let's retrain the model and plot the new predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X, y)\n",
    "y_pred = lr.predict(X)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.scatter(x, y)\n",
    "ax.plot(x, y_pred, color='red', linewidth=3)\n",
    "ax.set_title('Perfect fit');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the coefficients to see how they match those of the original function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "This concept of transforming existing features into new features (adding new columns to the input data) is called feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Problem 1\n",
    "<span  style=\"color:green; font-size:16px\">Create your own functional linear relationship similar to the one above. Perhaps use a trigonometric function and an exponential in the same equation. Then use a linear regression model to perfectly fit the data and to uncover the coefficients.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
