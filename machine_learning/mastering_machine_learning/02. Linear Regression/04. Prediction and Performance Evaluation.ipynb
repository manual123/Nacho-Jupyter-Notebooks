{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and Performance Evaluation\n",
    "\n",
    "Previously, we learned about the three-step process in scikit-learn to do machine learning. Once our model is trained, it's time to put it to use. We will learn how to make predictions with it and then to evaluate its performance by calculating $R^2$.\n",
    "\n",
    "## Repeating the three step machine learning process\n",
    "\n",
    "Let's repeat the three step machine learning process to build a linear regression model that uses above ground living area to predict sale price. Let's read in our sample housing dataset and select the single feature `GrLivArea` as our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "housing = pd.read_csv('../data/housing_sample.csv')\n",
    "X = housing[['GrLivArea']]\n",
    "y = housing['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import, Instantiate, Fit\n",
    "\n",
    "Let's complete the three-step process in a single cell by importing our estimator, instantiating, and training it with the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions with the `predict` method\n",
    "Now that our model is trained, we can use the `predict` method to make predictions. We must pass it a 2-dimensional numpy array (or single-column DataFrame) with the same number of columns as the one it was trained on. We used one feature during training, so we need a one-column array. Let's make predictions for houses with square footage of 500, 1,000, 3,000, and 5,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.array([[500], [1000], [3000], [5000]])\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass this two-dimensional array to the `predict` method to get the predicted sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.predict(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All those decimal places are excessive and make it difficult to read. Let's round our result to the nearest thousand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(new_data).round(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Could have used a DataFrame or list of lists\n",
    "\n",
    "Instead of using a numpy array to hold the new data, we could have used a single-column DataFrame or a list of lists. We begin by creating a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_data = pd.DataFrame({'GrLivArea': [500, 1000, 3000, 5000]})\n",
    "df_new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing it to the `predict` method returns the same exact values as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(df_new_data).round(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a list of lists where the inner list contains the value for the single feature also works and again returns the same predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_list = [[500], [1000], [3000], [5000]]\n",
    "lr.predict(new_data_list).round(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write our own function to calculate predictions\n",
    "\n",
    "We know the coefficients of our trained model and can build our own `predict` function with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    return lr.intercept_ + lr.coef_ * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the values are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(new_data).round(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the performance of our predictions\n",
    "\n",
    "It's only possible to evaluate the performance of our predictions if they are labeled with the ground truth. The only labeled observations we have are the ones we built the model from and are currently stored in variables `X` and `y`. \n",
    "\n",
    "### Evaluating on the training data is bad, but we will do it anyways\n",
    "\n",
    "The data that is used to train the model is called the **training data**. Typically, we would not use this same data to evaluate our model performance and instead choose labeled data that the model has not seen. We will learn formal processes for model evaluation later. For now, we will evaluate our model on the training data with the `score` method which returns $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the `score` method\n",
    "\n",
    "The `score` method uses the model built during the call to the `fit` method. It makes a prediction for each observation in `X`. It then calculates $R^2$ between this predicted value and the actual sale price $y$. Our linear regression model with a single feature obtained a score of .5 meaning that the sum of squared error from the model was 50% less than the sum of squared error produced by guessing the mean. In other words, our model explains 50% of the inherent variance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "<span  style=\"color:green; font-size:16px\">Use the garage area to build a simple linear regression model. What is the value of $R^2$ when scoring with the training data? What does the model predict for garage areas of size 100, 500, and 1000 square feet? Repeat this process for the other numeric features. Create your own arrays with new data to make predictions with.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
