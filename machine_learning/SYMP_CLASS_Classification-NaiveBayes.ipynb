{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classifying Warranty Claims with Symptom Class Names Using Machine Learning</h2><br><br>\n",
    "by Daniel J. Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At Honda Market Quality (MQ), we are responsible for identifying vehicle quality and safety problems.  The primary source of market or field information is warranty claims data.  This data represents the voice of our customers.  The data contains several attributes such as part number, part cost, days to failure, miles to failure, customer's complaint, etc.  Over the years, Honda has accumulated several millions of warranty claims.  In order to efficiently identify market problems, methods have to be employed to \"classify\" or group like or similar claims together so that analysis can be made to efficiently find trends, track problems, and ensure problems are fixed or counter-measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, warranty claims data is classified using several, hard-coded algorithms, requiring extensive maintenance.  The jobs that our IT runs to complete the classification take several hours overnight.  Due to recent advancements and accessibility of [machine learning](https://en.wikipedia.org/wiki/Machine_learning) (ML) methodologies, I believe MQ and our Honda IT professionals should investigate how ML can be used to improve the warranty claims classification process and extend its usage to other applicable areas of business.  Furthermore, I strongly believe MQ need to develop in-house capability and knowledge in machine learning.  Unfortunately at MQ, we do not have associates that are knowledgeable in ML or have limited knowledge, this includes me.  But we can change that and hopefully we can discover benefits of applying machine learning to enhance MQ's business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example is an attempt at a proof-of-concept of how machine learning can be used to classify warranty claims without hard-coded algorithms and is not meant to be representative of a \"production\" application.  The programming language used to employ the machine learning algorithm is Python using the [scikit-learn](http://scikit-learn.org/stable/) machine learning library.  This document is a [Jupyter](http://jupyter.org/) web notebook which allows me to document my process so that perhaps others can duplicate or understand my process as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to confidentiality, raw data will not be available.  Instead source of sample data was from an Excel file which I then \"copy/pasted\" from my computer's \"clipboard\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/pybokeh/Downloads/sample_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation: Data Cleansing and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source data had dollar sign and comma in the part cost amounts.  So we need to remove them and ensure the part cost is a numeric (float) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df['PART_COST_USD'] = df['PART_COST_USD'].str.replace('$','').str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df['PART_COST_USD'] = df['PART_COST_USD'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm data type of the source data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAIL_SHORT_PARTNO        object\n",
       "PART_COST_USD           float64\n",
       "DAYS_TO_FAIL_MINZERO      int64\n",
       "MILES_TO_FAIL             int64\n",
       "TEXT_CLUSTER_FAMILY      object\n",
       "SYMP_CLASS_NM            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the first 5 rows of the training data set we will use.  The features columns that we will use are the first 5 columns and the target or label data will be the last column (\"SYMPTOM_CLASS_NM\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we want to label or classify future claims based on part #, part cost, DTF, MTF, and symptom text cluster family to their appropriate symptom class name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's view our sample data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAIL_SHORT_PARTNO</th>\n",
       "      <th>PART_COST_USD</th>\n",
       "      <th>DAYS_TO_FAIL_MINZERO</th>\n",
       "      <th>MILES_TO_FAIL</th>\n",
       "      <th>TEXT_CLUSTER_FAMILY</th>\n",
       "      <th>SYMP_CLASS_NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00030</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOISE/VIBRATION</td>\n",
       "      <td>BRAKE JUDDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01469</td>\n",
       "      <td>458.91</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>FUNCTION ISSUE</td>\n",
       "      <td>BRAKE PEDAL SOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01469</td>\n",
       "      <td>455.32</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>FUNCTION ISSUE</td>\n",
       "      <td>MASTER CYLINDER/BOOSTER/POWER ASSY/FUNCTION ISSUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01611</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>COSMETIC ISSUE</td>\n",
       "      <td>SIDE PANEL / FENDER/FENDER (FRONT)/COSMETIC ISSUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04110</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0</td>\n",
       "      <td>20887</td>\n",
       "      <td>FUNCTION ISSUE</td>\n",
       "      <td>BULBS (INTERIOR)/04110/FUNCTION ISSUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FAIL_SHORT_PARTNO  PART_COST_USD  DAYS_TO_FAIL_MINZERO  MILES_TO_FAIL  \\\n",
       "0             00030           0.00                     0              2   \n",
       "1             01469         458.91                     0             11   \n",
       "2             01469         455.32                     0             10   \n",
       "3             01611           0.00                     0              5   \n",
       "4             04110           2.62                     0          20887   \n",
       "\n",
       "  TEXT_CLUSTER_FAMILY                                      SYMP_CLASS_NM  \n",
       "0     NOISE/VIBRATION                                       BRAKE JUDDER  \n",
       "1      FUNCTION ISSUE                                   BRAKE PEDAL SOFT  \n",
       "2      FUNCTION ISSUE  MASTER CYLINDER/BOOSTER/POWER ASSY/FUNCTION ISSUE  \n",
       "3      COSMETIC ISSUE  SIDE PANEL / FENDER/FENDER (FRONT)/COSMETIC ISSUE  \n",
       "4      FUNCTION ISSUE              BULBS (INTERIOR)/04110/FUNCTION ISSUE  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using machine learning algorithms, most require that the input data do not contain text/string data.  We can use scikit-learn's LabelEncoder() class to convert text/string data to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "part5_encoder = preprocessing.LabelEncoder()\n",
    "text_cluster_encoder = preprocessing.LabelEncoder()\n",
    "symp_class_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "part5_encoder.fit(df.FAIL_SHORT_PARTNO)\n",
    "text_cluster_encoder.fit(df.TEXT_CLUSTER_FAMILY)\n",
    "symp_class_encoder.fit(df.SYMP_CLASS_NM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create new columns containing the integer version of the columns that contain text/string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df['PART5'] = part5_encoder.transform(df.FAIL_SHORT_PARTNO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df['TEXT_CLUSTER'] = text_cluster_encoder.transform(df.TEXT_CLUSTER_FAMILY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df['SYMP_CLASS'] = symp_class_encoder.transform(df.SYMP_CLASS_NM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAIL_SHORT_PARTNO</th>\n",
       "      <th>PART_COST_USD</th>\n",
       "      <th>DAYS_TO_FAIL_MINZERO</th>\n",
       "      <th>MILES_TO_FAIL</th>\n",
       "      <th>TEXT_CLUSTER_FAMILY</th>\n",
       "      <th>SYMP_CLASS_NM</th>\n",
       "      <th>PART5</th>\n",
       "      <th>TEXT_CLUSTER</th>\n",
       "      <th>SYMP_CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00030</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOISE/VIBRATION</td>\n",
       "      <td>BRAKE JUDDER</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01469</td>\n",
       "      <td>458.91</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>FUNCTION ISSUE</td>\n",
       "      <td>BRAKE PEDAL SOFT</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01469</td>\n",
       "      <td>455.32</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>FUNCTION ISSUE</td>\n",
       "      <td>MASTER CYLINDER/BOOSTER/POWER ASSY/FUNCTION ISSUE</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01611</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>COSMETIC ISSUE</td>\n",
       "      <td>SIDE PANEL / FENDER/FENDER (FRONT)/COSMETIC ISSUE</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04110</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0</td>\n",
       "      <td>20887</td>\n",
       "      <td>FUNCTION ISSUE</td>\n",
       "      <td>BULBS (INTERIOR)/04110/FUNCTION ISSUE</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FAIL_SHORT_PARTNO  PART_COST_USD  DAYS_TO_FAIL_MINZERO  MILES_TO_FAIL  \\\n",
       "0             00030           0.00                     0              2   \n",
       "1             01469         458.91                     0             11   \n",
       "2             01469         455.32                     0             10   \n",
       "3             01611           0.00                     0              5   \n",
       "4             04110           2.62                     0          20887   \n",
       "\n",
       "  TEXT_CLUSTER_FAMILY                                      SYMP_CLASS_NM  \\\n",
       "0     NOISE/VIBRATION                                       BRAKE JUDDER   \n",
       "1      FUNCTION ISSUE                                   BRAKE PEDAL SOFT   \n",
       "2      FUNCTION ISSUE  MASTER CYLINDER/BOOSTER/POWER ASSY/FUNCTION ISSUE   \n",
       "3      COSMETIC ISSUE  SIDE PANEL / FENDER/FENDER (FRONT)/COSMETIC ISSUE   \n",
       "4      FUNCTION ISSUE              BULBS (INTERIOR)/04110/FUNCTION ISSUE   \n",
       "\n",
       "   PART5  TEXT_CLUSTER  SYMP_CLASS  \n",
       "0      0             3         161  \n",
       "1      6             1         162  \n",
       "2      6             1        1708  \n",
       "3      7             0        2280  \n",
       "4     11             1         248  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to save the encoders for use later on un-classified data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Data Structure Persistence using Python's pickle library: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Encoders to disk\n",
    "pickle.dump(part5_encoder, open(r'C:\\Users\\pybokeh\\Dropbox\\python\\jupyter_notebooks\\machine_learning\\part5_encoder.sk','wb'))\n",
    "pickle.dump(text_cluster_encoder, open(r'C:\\Users\\pybokeh\\Dropbox\\python\\jupyter_notebooks\\machine_learning\\text_cluster_encoder.sk','wb'))\n",
    "pickle.dump(symp_class_encoder, open(r'C:\\Users\\pybokeh\\Dropbox\\python\\jupyter_notebooks\\machine_learning\\symp_class_encoder.sk','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**-For the sake of simplicity, I resorted to saving the mappings using Python's pickle object serialization library.  In a production environment, it would be more suitable to use a relational database to store the mappings in a table instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are ready to create our features input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our features data will consist of: part5, part cost, DTF, MTF, and symptom text cluster (all represented with numeric values thanks to my mappings made earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "features = df[['PART5','PART_COST_USD','DAYS_TO_FAIL_MINZERO','MILES_TO_FAIL','TEXT_CLUSTER']].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our features data does not contain text/string data.  Let's look at the first 10 rows of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 0.0, 2.0, 3.0],\n",
       " [6.0, 458.91, 0.0, 11.0, 1.0],\n",
       " [6.0, 455.32, 0.0, 10.0, 1.0],\n",
       " [7.0, 0.0, 0.0, 5.0, 0.0],\n",
       " [11.0, 2.62, 0.0, 20887.0, 1.0],\n",
       " [11.0, 4.37, 0.0, 11849.0, 1.0],\n",
       " [12.0, 3.04, 0.0, 3.0, 6.0],\n",
       " [13.0, 0.0, 0.0, 5.0, 4.0],\n",
       " [19.0, 0.0, 0.0, 11.0, 0.0],\n",
       " [19.0, 0.0, 0.0, 14.0, 0.0]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of rows in our features data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81403"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create our target/label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "labels = df.SYMP_CLASS.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 10 label data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[161, 162, 1708, 2280, 248, 248, 1247, 2343, 2293, 2293]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of rows in our label data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81403"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning the Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our features training data should contain 80% of our original complete data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65122"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[415.0, 81.22, 891.0, 1887.0, 6.0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "features_train_std = stdsc.fit_transform(features_train)\n",
    "features_test_std = stdsc.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.86131084,  -0.09973194,   1.05144666,  -0.93794294,\n",
       "          1.81290566],\n",
       "       [  0.9911888 ,  -0.1773592 ,   0.04145509,   1.25145102,\n",
       "         -1.14746417],\n",
       "       [  1.38262607,   0.09687569,  -0.22257824,  -0.31504457,  -0.6540692 ],\n",
       "       [  1.86964685,   0.18940672,   0.7002567 ,   0.28702583,\n",
       "         -1.14746417],\n",
       "       [ -0.38111744,   1.42289478,   1.57438645,   0.45636622,\n",
       "          0.82611572],\n",
       "       [ -1.7261141 ,   0.20117431,   1.86661752,   2.95268154,\n",
       "         -1.14746417],\n",
       "       [ -1.1389582 ,  15.87116858,   0.118358  ,   0.5200144 ,\n",
       "         -0.16067423],\n",
       "       [  0.71809303,  -0.22817634,   0.63617094,   1.45384448,\n",
       "         -1.14746417],\n",
       "       [  1.77633913,  -0.11768862,  -0.49942872,  -0.03554885,\n",
       "         -1.14746417],\n",
       "       [ -1.26640289,  -0.2644505 ,   1.69486768,   0.12311882,\n",
       "          1.81290566],\n",
       "       [ -0.86131084,  -0.13039984,   1.45903209,   0.71212324,  -0.6540692 ],\n",
       "       [ -0.86131084,  -0.09973194,  -0.16618277,  -0.65650672,  -0.6540692 ],\n",
       "       [ -0.35608366,  -0.30918956,   1.08220782,   0.99213643,  -0.6540692 ],\n",
       "       [  1.54420773,  -0.31976374,   0.03120137,  -0.30281947,  -0.6540692 ],\n",
       "       [ -0.86131084,  -0.09973194,   1.18474504,   0.36276975,  -0.6540692 ],\n",
       "       [  1.53738033,  -0.2995035 ,  -0.2277051 ,   0.10500755,  -0.6540692 ],\n",
       "       [ -0.11940066,  -0.32514797,  -0.13029475,  -0.1797275 ,\n",
       "         -1.14746417],\n",
       "       [  1.54420773,  -0.32514797,  -0.28410057,   0.52195489,\n",
       "         -0.16067423],\n",
       "       [ -0.86131084,  -0.100176  ,  -0.18412679,   0.09045385,  -0.6540692 ],\n",
       "       [  1.38262607,   0.09687569,  -0.39432808,  -0.32377679,  -0.6540692 ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_std[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now use scikit-learn's NaiveBayes Gaussian classification algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ML classification algorithms to choose from.  Since I do not know the internal implementation of each and every algorithm, I had to resort to trial-and-error in finding the algorithm which gave me the best results, and quite frankly, I am not knowledgeable on how to perform proper model validation.  The model that gave me best results using large data set was the Naive Bayes classification algorithm.  With smaller data sets, decision tree or random forest algorithm gave me good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the training data and target/label data.  Again, the training data is the part #, part cost, DTF, MTF, and symptom text cluster.  The label data is the symptom class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(features_train_std, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "classes = np.unique(labels_train)\n",
    "\n",
    "sgdc = SGDClassifier(loss=\"log\", penalty=\"l2\")\n",
    "# sgdc.partial_fit(features_train_std, labels_train, classes=classes)\n",
    "sgdc.fit(features_train_std, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=1)\n",
    "rfc.fit(features_train_std, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict just one record.**  Here I will feed the prediction model a transmission part # (06200), an arbitrary part cost ($2000), arbitrary DTF (0), MTF (5), and symptom text cluster (\"WARNING LIGHT ON\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STEERING SYSTEM/O-RING/WARNING LIGHT ON'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criteria = [part5, part cost, dtf, mtf, symptom]\n",
    "criteria = [part5_encoder.transform(['06200']), 2000, 0, 5, text_cluster_encoder.transform(['WARNING LIGHT ON'])]\n",
    "inv_criteria = stdsc.inverse_transform(criteria)\n",
    "symp_class_encoder.inverse_transform(rfc.predict([inv_criteria]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing this to the source data, this is correct and makes sense!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting 10 records:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.86131084,  -0.09973194,   1.05144666,  -0.93794294,\n",
       "          1.81290566],\n",
       "       [  0.9911888 ,  -0.1773592 ,   0.04145509,   1.25145102,\n",
       "         -1.14746417],\n",
       "       [  1.38262607,   0.09687569,  -0.22257824,  -0.31504457,  -0.6540692 ],\n",
       "       [  1.86964685,   0.18940672,   0.7002567 ,   0.28702583,\n",
       "         -1.14746417],\n",
       "       [ -0.38111744,   1.42289478,   1.57438645,   0.45636622,\n",
       "          0.82611572],\n",
       "       [ -1.7261141 ,   0.20117431,   1.86661752,   2.95268154,\n",
       "         -1.14746417],\n",
       "       [ -1.1389582 ,  15.87116858,   0.118358  ,   0.5200144 ,\n",
       "         -0.16067423],\n",
       "       [  0.71809303,  -0.22817634,   0.63617094,   1.45384448,\n",
       "         -1.14746417],\n",
       "       [  1.77633913,  -0.11768862,  -0.49942872,  -0.03554885,\n",
       "         -1.14746417],\n",
       "       [ -1.26640289,  -0.2644505 ,   1.69486768,   0.12311882,\n",
       "          1.81290566]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = features_train_std[:10]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEAD BATTERY (BATTERY ONLY REPL)\n",
      "TAILGATE / TRUNK/GARNISH/COSMETIC ISSUE\n",
      "HVAC/BLOWER MOTOR/FUNCTION ISSUE\n",
      "DOORS (FRONT)/LINER/COSMETIC ISSUE\n",
      "HVAC/COMPRESSOR/FUNCTION ISSUE\n",
      "OTHER/04746/COSMETIC ISSUE\n",
      "OTHER/1A001 MOTOR   TRANSMISSION/LEAK\n",
      "DOORS (REAR)/SEAL/COSMETIC ISSUE\n",
      "SUNVISOR/VISOR/COSMETIC ISSUE\n",
      "EVAP\n"
     ]
    }
   ],
   "source": [
    "for name in symp_class_encoder.inverse_transform(labels_train[:10]):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAP SYSTEM COMPONENT/SENSOR/WARNING LIGHT ON\n",
      "TAILGATE / TRUNK/GARNISH/COSMETIC ISSUE\n",
      "HVAC/BLOWER MOTOR/FUNCTION ISSUE\n",
      "FRONT WINDSHIELD/COWL/COSMETIC ISSUE\n",
      "HVAC/COMPRESSOR/FUNCTION ISSUE\n",
      "OTHER/04746/COSMETIC ISSUE\n",
      "OTHER/1A001 MOTOR   TRANSMISSION/LEAK\n",
      "FRONT WINDSHIELD/COWL/COSMETIC ISSUE\n",
      "FRONT WINDSHIELD/COWL/COSMETIC ISSUE\n",
      "EVAP SYSTEM COMPONENT/FUEL FILLER CAP/WARNING LIGHT ON\n"
     ]
    }
   ],
   "source": [
    "for item in test_data:\n",
    "    print(symp_class_encoder.inverse_transform(clf.predict([item]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEAD BATTERY (BATTERY ONLY REPL)\n",
      "TAILGATE / TRUNK/GARNISH/COSMETIC ISSUE\n",
      "HVAC/BLOWER MOTOR/FUNCTION ISSUE\n",
      "DOORS (FRONT)/LINER/COSMETIC ISSUE\n",
      "HVAC/COMPRESSOR/FUNCTION ISSUE\n",
      "OTHER/04746/COSMETIC ISSUE\n",
      "OTHER/1A001 MOTOR   TRANSMISSION/LEAK\n",
      "DOORS (REAR)/SEAL/COSMETIC ISSUE\n",
      "SUNVISOR/VISOR/COSMETIC ISSUE\n",
      "EVAP\n"
     ]
    }
   ],
   "source": [
    "for item in test_data:\n",
    "    print(symp_class_encoder.inverse_transform(rfc.predict([item]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPMS LIGHT ON\n",
      "AC LOW FILL / TEST\n",
      "HVAC/BLOWER MOTOR/FUNCTION ISSUE\n",
      "HVAC/BLOWER MOTOR/FUNCTION ISSUE\n",
      "DEAD BATTERY (BATTERY ONLY REPL)\n",
      "DEAD BATTERY (BATTERY ONLY REPL)\n",
      "AUDIO SYSTEM/HEAD UNIT/FUNCTION ISSUE\n",
      "AC LOW FILL / TEST\n",
      "TAILGATE / TRUNK/GARNISH/COSMETIC ISSUE\n",
      "TPMS LIGHT ON\n"
     ]
    }
   ],
   "source": [
    "for item in test_data:\n",
    "    print(symp_class_encoder.inverse_transform(sgdc.predict([item]))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the above output to the source data, all but 1 was not classified as the original source.  This is pretty good considering generally symptom class name assignments are not completely accurate anyways AND were not expected to be.  Warranty data is inherently dirty data and is reflected in the not-so-perfect symptom class names.  So the performance of my ML classification attempt looks very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Using the Machine Learning Model to Classify Future Claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist the model so that we can re-use it without having to retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(clf1, open(r'D:\\jupyter\\machine_learning\\nbayes.sk','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-use the Model and Load Helper Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "clf2 = pickle.load(open(r'D:\\jupyter\\machine_learning\\nbayes.sk','rb'))\n",
    "\n",
    "# Load helper data structures that we made earlier\n",
    "part5_to_int_mapper = pickle.load(open(r'D:\\jupyter\\machine_learning\\part5_to_int_mapper.sk', 'rb'))\n",
    "symptom_to_int_mapper = pickle.load(open(r'D:\\jupyter\\machine_learning\\symptom_to_int_mapper.sk', 'rb'))\n",
    "int_to_symp_class_mapper = pickle.load(open(r'D:\\jupyter\\machine_learning\\int_to_symp_class_mapper.sk', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, in a production environment, it is probably best to load the mappings from a relational database instead of using Python's pickle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a single observation using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEAT BELTS/REAR/COSMETIC ISSUE'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criteria = [part5, part cost, dtf, mtf, symptom]\n",
    "criteria = [part5_to_int_mapper['04823'], 0, 0, 207, symptom_to_int_mapper['COSMETIC ISSUE']]\n",
    "int_to_symp_class_mapper[clf2.predict([criteria])[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That's it!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of symptom class names, we can classify warranty claims with other different types of classification labels so this classification example can be extended for any other classification we can come up with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not tested this model extensively with other larger test data, but so far I have been impressed with the model so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small-scale example shows that a machine learning classification algorithm was able to classify warranty claims without hard-coded algorithms.  It was \"trained\" solely from the training data consisting of just some of the attributes of the warranty claims data."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
