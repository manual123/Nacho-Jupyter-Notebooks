---
title: "Data Frames and Exploratory Data Analysis"
author: "Jose A. Dianes"
date: "10 July 2015"
output:
  html_document:
    keep_md: yes
---

## Downloading files and reading CSV  

In R, you use `read.csv` to read CSV files into `data.frame` variables. Although the R function `read.csv` can work with URLs, https is a problem for R in many cases, so you need to use a package like RCurl to get around it.  

```{r}
library(RCurl)
existing_cases_file <- getURL("https://docs.google.com/spreadsheets/d/1X5Jp7Q8pTs3KLJ5JBWKhncVACGsg5v4xu6badNs4C7I/pub?gid=0&output=csv")
existing_df <- read.csv(text = existing_cases_file, row.names=1, stringsAsFactor=F)
str(existing_df)
```

The `str()` function in R gives us information about a variable type. In this case
we can see that, due to the `,` thousands separator, some of the columns hasn't been parsed as numbers but as character. If we want to properly work with our dataset we need to convert them to numbers.  

Once we know a bit more about indexing and mapping functions, I promise you will be able to understand the following piece of code. By know let's say that we convert a column and assign it again to its reference in the data frame.    

```{r}
existing_df[c(1,2,3,4,5,6,15,16,17,18)] <- 
    lapply( existing_df[c(1,2,3,4,5,6,15,16,17,18)], 
            function(x) { as.integer(gsub(',', '', x) )})
str(existing_df)
```

Everything looks fine now. But still our dataset is a bit tricky. If we have a 
look at what we got into the data frame with `head`  

```{r}
head(existing_df,3)
```

and `nrow` and `ncol`

```{r}
nrow(existing_df)
ncol(existing_df)
```

we see that we have a data frame with 207 observations, one for each country, and 19 variables or features, one for each year. This doesn't seem the most natural shape for this dataset. It is very unlikely that we will add new countries (observations or rows in this case) to the dataset, while is quite possible to add additional years (variables or columns in this case). If we keep it like it is, we will end up with a dataset that grows in features and not in observations, and that seems counterintuitive (and unpractical depending of the analysis we will want to do).  

We won't need to do this preprocessing all the time, but there we go. Thankfully, R as a function `t()` similar to the method `T` in Pandas, that allows us to traspose a `data.frame` variable. The result is given as a `matrix`, so we need to convert it to a data frame again by using `as.data.frame`.    

```{r}
# we will save the "trasposed" original verison for later use if needed
existing_df_t <- existing_df 
existing_df <- as.data.frame(t(existing_df))
head(existing_df,3)
```

Row names are sort of what in Pandas we get when we use the attribute `.index` in a data frame.

```{r}
rownames(existing_df)
```

In our data frame we see we have weird names for them. Every year is prefixed with an X. This is so because they started as column names. From the definition of a `data.frame` in R, we know that each column is a vector with a variable name. A name in R cannot start with a digit, so R automatically prefixes numbers with the letter X. Right know we will leave it like it is since it doesn't really stop us from doing our analysis.  

In the case of column names, they pretty much correspond to Pandas `.columns` attribute in a data frame.  

```{r}
colnames(existing_df)
```

These two functions show a common idiom in R, where we use the same function to get a value and to assign it. For example, if we want to change row names we will do something like:

`colnames(existing_df) <- new_col_names`  

But as we said we will leave them as they are by now.  

## Data indexing  

Similarly to what we do in Pandas (actually Pandas is inspired in R), we can
access a `data.frame` column by its position.  

```{r}
existing_df[,1]
```

The position-based indexing in `R` uses the first element for the row number and
the second one for the column one. If left blank, we are telling R to get all
the row/columns. In the previous example we retrieved all the rows for the first
column (Afghanistan) in the `data.frame`. And yes, R has a **1-based** indexing 
schema.  

Like in Pandas, we can use column names to access columns (series in Pandas).
However R `data.frame` variables aren't exactly object and we don't use the `.`
operator but the `$` that allows accessing labels within a list.  

```{r}
existing_df$Afghanistan
```

An finally, since a `data.frame` is a list of elements (its columns), we can access
columns as list elements using the list indexing operator `[[]]`.  

```{r}
existing_df[[1]]
```

At this point you should have realised that in R there are multiple ways of doing
the same thing, and that this seems to happen more because of the language itself
than because somebody wanted to provide different ways of doing things. This strongly
contrasts with Python's philosophy of having one clear way of doing things (the 
Pythonic way).  

For row indexing we have the positional approach.  

```{r}
existing_df[1,]
```

There we retrieved data for every country in 1990. We can combine this with a
column number.  

```{r}
existing_df[1,1]
```

Or its name.  

```{r}
existing_df$Afghanistan[1]
```

What did just do before? Basically we retrieved a column, that is a vector, and
accessed that vector first element. That way we got the value for Afghanistan for
the year 1990. We can do the same thing using the `[[]]` operator instead of the
list element label.  

```{r}
existing_df[[1]][1]
```

We can also select multiple columns and/or rows by passing R vectors.  

```{r}
existing_df[c(3,9,16),c(170,194)]
```

Finally, using names is also possible when using positional indexing.  

```{r}
existing_df["X1992","Spain"]
```

That we can combine with vectors.  

```{r}
existing_df[c("X1992", "X1998", "X2005"), c("Spain", "United Kingdom")]
```

So enough about indexing. In the next section we will see how to perform more 
complex data accessing using conditional selection.  

## Data Selection  

As we did with Pandas, let's check the result of using a `data.frame` in a logical
or boolean expression.  

```{r}
existing_df_gt10 <- existing_df>10
head(existing_df_gt10,2) # check just a couple of rows
```

In this case we get a `matrix` variable, with boolean values. When applied to
individual columns.  

```{r}
existing_df['United Kingdom'] > 10
```

The result (and the syntax) is equivalent to that of Pandas, and can be used for
indexing as follows.  

```{r}
existing_df$Spain[existing_df['United Kingdom'] > 10]
```

As we did in Python/Pandas, let's use the whole boolean matrix we got before.  

```{r}
head(existing_df[ existing_df_gt10 ]) # check first few elements
```

But hey, the results are quite different from what we would expect comming from
using Pandas. We got a long vector of values, not a data frame. The problem is 
that the `[ ]` operator, when passed a matrix, first coherces the data frame to a
matrix. Basically we cannot seamlessly work with R data.frames and boolean matrices
as we did with Pandas. We should instead index in both dimensions, columns and rows,
separatelly.  

But still, we can use matrix indexing with a data frame to replace elements.  

```{r}
existing_df_2 <- existing_df
existing_df_2[ existing_df_gt10 ] <- -1
head(existing_df_2,2)
```

We can see how many of the elements, those where we had more than 10 cases, where
assigned a -1 value.  

The most expressive way of selecting form a `data.frame` in R is by using the 
`subset` function (type `?subset` in your R console to
read about this function). The function is applied by row in the data frame. 
The second argument can include any condition using column names. The third argument
can include a list of columns. The resulting dataframe will contain those rows
that satisfy the second argument conditions, including just those columns listed
in the third argument (all of them bt default). For example, if we want to select
those years when the United Kingdom had more than 10 cases, and list the resulting
rows for three countries (UK, Spain, and Colombia) we will use:    

```{r}
# If a column name contains blanks, we can have to use ` `
subset(existing_df,  `United Kingdom`>10, c('United Kingdom', 'Spain','Colombia'))
```

We can do the same thing using `[ ]` as follows.  

```{r}
existing_df[existing_df["United Kingdom"]>10, c('United Kingdom', 'Spain','Colombia')]
```

## Function mapping and grouping  

### `lapply`  

R has a long collection of *apply* functions that can be used to apply functions to
elements within vectors, matrices, lists, and data frames. The one we will introduce here
is **lapply** (type `?lapply` in your R console). It is the one we use with lists and, 
since a data frame is a list of column vectors, will work with them as well.  

For example, we can repeat the by year sum we did with Pandas as follows.  

```{r}
existing_df_sum_years <- lapply(existing_df, function(x) { sum(x) })
existing_df_sum_years <- as.data.frame(existing_df_sum_years)
existing_df_sum_years
```

What did we do there? Very simple. the `lapply` function gets a list and a function
that will be applied to each element. It returns the result as a list. The function 
is defined in-line (i.e. as a lambda in Python). For a given `x` if sums its elements.  

If we want to sum by year, for every country, we can use the trasposed data frame
we stored before.  

```{r}
existing_df_sum_countries <- lapply(existing_df_t, function(x) { sum(x) })
existing_df_sum_countries <- as.data.frame(existing_df_sum_countries)
existing_df_sum_countries
```

#### aggregate  

R provided basic grouping functionality by using `aggregate`. Another option is
to have alook at the powerful [dplyr](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html) library that I highly recommend.  

But `aggregate` is quite powerful as well. It accepts a data frame, a list of 
grouping elements, and a function to apply to each group. First we need to define
a grouping vector.  

```{r}
before_2000 <- c('1990-99','1990-99','1990-99','1990-99','1990-99',
                 '1990-99','1990-99','1990-99','1990-99','1990-99',
                 '2000-07','2000-07','2000-07','2000-07','2000-07',
                 '2000-07','2000-07','2000-07')
before_2000
```

Then we can use that column as groping element and use the function `mean`.  

```{r}
mean_cases_by_period <- aggregate(existing_df, list(Period = before_2000), mean)
mean_cases_by_period
```

The `aggregate` function allows subsetting the dataframe we pass as first parameter
of course, and also to pass multiple grouping elements and define our own functions
(either as lambda or predefined functions). And again, the result is a data frame
that we can index as usual.  

```{r}
mean_cases_by_period[,c('United Kingdom','Spain','Colombia')]
```

## Descriptive statistics  

The basic descriptive statistics method in R is, as we said, the function `summary()`.  

```{r}
existing_summary <- summary(existing_df)
str(existing_summary)
```

It returns a table object where we have summary statistics for each of the columns in a data frame. A table object is good for visualising data, but not so good for accessing and indexing it as a data frame. Basically we access it as a matrix, using positional indexing. If we want the first column, that corresponding to Afghanistan, we do.      

```{r}
existing_summary[,1]
```

A trick we can to access by column name is use the column names in the original data frame. We also can build a new data frame with the results.    

```{r}
data.frame(
    Spain=existing_summary[,which(colnames(existing_df)=='Spain')],
    UK=existing_summary[,which(colnames(existing_df)=='United Kingdom')])
```

Being R a functional language, we can apply functions such as `sum`, `mean`, `sd`, etc. to vectors. Remember that a data frame is a list of vectors (i.e. each column is a vector of values), so we can easily use these functions with columns. We can finally combine these functions with `lapply` or `sapply` and apply them to multiple columns in a data frame.  

However, there is a family of functions in R that can be applied to columns or rows in order to get means and sums directly. These are more efficient than using apply functions, and also allows us to apply them not just by columns but also by row. If you type `?colSums' for example, the help page describes all of them.  

For example, we can easily obtain the average number of existing cases per year with a single call.  

```{r}
rowMeans(existing_df)
```


## Plotting  

Base plotting in R is not very sophisticated when compared with ggplot2, but still
is powerful and handy because many data types have implemented custom `plot()` methods
that allow us to plot them with a single method call. However this is not always the
case and more often than not we will need to pass the right set of elements to our basic plotting functions.  

Let's start with a basic line chart like we did with Python/Pandas.  

```{r}
uk_series <- existing_df[,c("United Kingdom")]
spain_series <- existing_df[,c("Spain")]
colombia_series <- existing_df[,c("Colombia")]
```

```{r}
xrange <- 1990:2007
plot(xrange, uk_series, 
     type='l', xlab="Year", 
     ylab="Existing cases per 100K", 
     col = "blue", 
     ylim=c(0,100))
lines(xrange, spain_series,
      col = "darkgreen")
lines(xrange, colombia_series, 
      col = "red")
legend(x=2003, y=100, 
       lty=1, cex=.7,
       col=c("blue","darkgreen","red"), 
       legend=c("UK","Spain","Colombia"))
```

You can compare how easy was to plot three series in Pandas, and how doing the
same thing **with basic plotting** in R gets more verbose. At least we need
three function calls, those for plot and line, and then we have the legend, etc. The base plotting in R is really intended to make quick and dirty charts.  

Now with box plots.  

```{r}
boxplot(uk_series, spain_series, colombia_series, 
        names=c("UK","Spain","Colombia"),
        xlab="Year", 
        ylab="Existing cases per 100K")
```

This one was way shorter, and we don't even need colours or a legend.  

## Answering questions

We already know that we can use `max` with a data frame column in R and get the maximum value. Additionally, we can use `which.max` in order to get its position (similarly to the use og `argmax` in Pandas). If we use the trasposed dataframe, we can use `lapply` or `sapply` to perform this operation in every year column, getting then either a list or a vector of indices (we will use `sapply` that returns a vector). We just need a little tweak and use a countries vector that we will index to get the country name instead of the index as a result.  

```{r}
country_names <- rownames(existing_df_t)
sapply(existing_df_t, function(x) {country_names[which.max(x)]})
```

###### World trens in TB cases  

Again, in order to explore the world general tendency, we need to sum up every countries’ values for the three datasets, per year. 

But first we need to load the other two datasets for number of deaths and number of new cases. 

```{r}
# Download files
deaths_file <- getURL("https://docs.google.com/spreadsheets/d/12uWVH_IlmzJX_75bJ3IH5E-Gqx6-zfbDKNvZqYjUuso/pub?gid=0&output=CSV")
new_cases_file <- getURL("https://docs.google.com/spreadsheets/d/1Pl51PcEGlO9Hp4Uh0x2_QM0xVb53p2UDBMPwcnSjFTk/pub?gid=0&output=csv")

# Read into data frames
deaths_df <- read.csv(text = deaths_file, row.names=1, stringsAsFactor=F)
new_df <- read.csv(text = new_cases_file, row.names=1, stringsAsFactor=F)

# Cast data to int (deaths doesn't need it)
new_df[1:18] <- lapply(new_df[1:18], function(x) { as.integer(gsub(',', '', x) )})

# Transpose
deaths_df_t <- deaths_df
deaths_df <- as.data.frame(t(deaths_df))
new_df_t <- new_df
new_df <- as.data.frame(t(new_df))
```

And now the sums by row. We need to convert to a data frame since the function returns a numeric vector.  

```{r}
deaths_total_per_year_df <- data.frame(total=rowSums(deaths_df))
existing_total_per_year_df <- data.frame(total=rowSums(existing_df))
# We pass na.rm = TRUE in order to ignore missing values in the new
# cases data frame when summing (no missing values in other dataframes though)
new_total_per_year_df <- data.frame(total=rowSums(new_df, na.rm = TRUE))
```

Now we can plot each line using what we have learnt so far. In order to get a vector with the counts to pass to each plotting function, we use R data frame indexing selecting the first row and all the columns (`[1,]`).  

```{r}
xrange <- 1990:2007
plot(xrange, deaths_total_per_year_df$total, 
     type='l', xlab="Year", 
     ylab="Count per 100K", 
     col = "blue", 
     ylim=c(0,50000))
lines(xrange, existing_total_per_year_df$total,
      col = "darkgreen")
lines(xrange, new_total_per_year_df$total, 
      col = "red")
legend(x=1992, y=52000, 
       lty=1, 
       cex = .7,
       ncol = 3,
       col=c("blue","darkgreen","red"), 
       legend=c("Deaths","Existing cases","New cases"))
```

The conclusions are obviously the same as when using Python.  

###### Countries out of tendency  

So what countries are out of that tendency (for bad)? Again, in order to find this out, first we need to know the distribution of countries in an average year. We use `colMeans` for that purpose.    

```{r}
deaths_by_country_mean <- data.frame(mean=colMeans(deaths_df))
existing_by_country_mean <- data.frame(mean=colMeans(existing_df))
new_by_country_mean <- data.frame(mean=colMeans(new_df, na.rm=TRUE))
```

We can plot these distributions to have an idea of how the countries are distributed in an average year. We are not so interested about the individual countries but about the distribution itself.    

```{r}
barplot(sort(deaths_by_country_mean$mean))
```

Again we can see there are someway three sections, with a slowly decreasing part at the beginning, a second more step section, and a final peak that is clearly apart from the rest.  

Let's skip this time the 1.5-outlier part and go diretcly to the 5.0-outliers. In R we will use a different approach we will use the `quantile()` function in order to get the inter-quartile range and determine the outlier threshold.  

Since we already know the results from our Python section, let's do it just for the new cases, so we generate also the plots we did before.  


```{r}
new_super_outlier <- 
    quantile(new_by_country_mean$mean, probs = c(.5)) * 5.0
super_outlier_countries_by_new_index <- 
    new_by_country_mean > new_super_outlier
```

And the proportion is.  

```{r}
sum(super_outlier_countries_by_new_index)/208
```

Let's obtain a data frame from this, with just those countries we consider to be outliers.  

```{r}
super_outlier_new_df <- new_df[, super_outlier_countries_by_new_index ]
```

Now we are ready to plot them.  

```{r}
xrange <- 1990:2007
plot(xrange, super_outlier_new_df[,1], 
     type='l', xlab="Year", 
     ylab="New cases per 100K", 
     col = 1, 
     ylim=c(0,1800))
for (i in seq(2:ncol(super_outlier_new_df))) {
    lines(xrange, super_outlier_new_df[,i],
    col = i)
}
legend(x=1990, y=1800, 
       lty=1, cex = 0.5,
       ncol = 7,
       col=1:22,
       legend=colnames(super_outlier_new_df))
```

Definitely we can see here an advantage of using Pandas basic plotting versus R basic plotting!  

So far our results match. We have 22 countries where the number of new cases on an average year is greater than 5 times the median value of the distribution. Let’s create a country that represents on average these 22. We will use `rowMeans()` here.    

```{r}
average_countries_df <- 
    data.frame(
        averageOutlierMean=rowMeans(super_outlier_new_df, na.rm=T)
    )
average_countries_df
```

Now let’s create a country that represents the rest of the world.  

```{r}
average_countries_df$averageBetterWorldMean <- 
    rowMeans(new_df[ ,- super_outlier_countries_by_new_index ], na.rm=T)
average_countries_df
```

Now let’s plot the outlier country with the average world country.  

```{r}
xrange <- 1990:2007
plot(xrange, average_countries_df$averageOutlierMean, 
     type='l', xlab="Year", 
     ylab="New cases per 100K", 
     col = "darkgreen", 
     ylim=c(0,600))
lines(xrange, average_countries_df$averageBetterWorldMean, col = "blue")
legend(x=1990, y=600, 
       lty=1, cex = 0.7,
       ncol = 2,
       col=c("darkgreen","blue"),
       legend=c("Average outlier country", "Average World Country"))
```

