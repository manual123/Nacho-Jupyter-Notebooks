{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization\n",
    "Let's take a look at few rows from some visits to a doctor in the `tidy/doctor_visits.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dv = pd.read_csv('../data/tidy/doctor_visits.csv')\n",
    "dv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The information is easy to read\n",
    "All the information presented in this table is easy to read. Any question that is asked about the visits can be quickly answered.\n",
    "\n",
    "### Yet, something is wrong, what is it?\n",
    "Although the table of data is sufficient to address our questions, it repeats much of the data and will not scale well as more patients come into the system. It will also be difficult to update historical data, such as if the patient's address changes or a clinic changes names.\n",
    "\n",
    "### A short intro into data normalization\n",
    "Modern databases attempt to reduce the amount of replication in the data by a process called **normalization**. It involves separating data into tables to minimize replication and increase data accuracy.\n",
    "\n",
    "From [wikipedia](https://en.wikipedia.org/wiki/Database_normalization):\n",
    "> Database Normalization, or simply normalization, is the process of organizing the columns (attributes) and tables (relations) of a relational database to reduce data redundancy and improve data integrity. Normalization is also the process of simplifying the design of a database so that it achieves the optimum structure. It reduces and eliminates redundant data. In normalization, data integrity is assured. It was first proposed by Dr. Edgar F. Codd, as an integral part of a relational model.\n",
    "\n",
    "There is much, much more to data normalization. The following example is just a brief overview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which values are always the same for each visit?\n",
    "When looking through the table, you should notice that certain values will repeat for every single visit. For instance, the patient name, address, and birth date are going to be the same. There isn't a need to keep repeating all these values for every visit.\n",
    "\n",
    "### Separating patient values into a distinct table\n",
    "Let's select all the patient columns in a single DataFrame. The **`copy`** method is called to ensure that this is new DataFrame is a completely different DataFrame and not referring to the same data as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = dv[['patient_name', 'patient_address', 'patient_birthdate']]\n",
    "patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicate rows\n",
    "There is no need to store duplicate values of each row. Let's keep only the unique rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = patient.drop_duplicates()\n",
    "patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a primary key to uniquely identify each row\n",
    "When we normalize our data, and separate it into new tables, an additional column is added to the table to uniquely identify each row. The unique value that identifies each row is called a **primary key**. Let's add a primary key to the patient table. Note: If you get the **`SettingWithCopyWarning`**, ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient['patient_id'] = np.arange(len(patient))\n",
    "patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrange the columns so that `patient_id` is first\n",
    "It's best to always put the primary key as the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['patient_id', 'patient_name', 'patient_address', 'patient_birthdate']\n",
    "patient = patient[cols]\n",
    "patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We just created a dimension\n",
    "In database terminology, the patient table would be considered a **dimension**. Dimensions are things that exist in your data that are independent of any event taking place. They tend to be static and do not change often (such as your name or birth date.\n",
    "\n",
    "### Create tables for all the other dimensions\n",
    "There are several other dimensions in our original table. Let's create new dimension tables for each one of the following:\n",
    "\n",
    "* clinic\n",
    "* doctor\n",
    "* procedure\n",
    "\n",
    "We will select each of the columns unique to each dimension, drop the replicated rows and add a primary key as the first column to uniquely identify each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinic Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['clinic_name', 'clinic_address']\n",
    "clinic = dv[cols].drop_duplicates()\n",
    "clinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic['clinic_id'] = np.arange(len(clinic))\n",
    "clinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['clinic_id', 'clinic_name', 'clinic_address']\n",
    "clinic = clinic[cols]\n",
    "clinic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doctor Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['doctor_name', 'doctor_specialty']\n",
    "doctor = dv[cols].drop_duplicates()\n",
    "doctor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor['doctor_id'] = np.arange(len(doctor))\n",
    "doctor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['doctor_id', 'doctor_name', 'doctor_specialty']\n",
    "doctor = doctor[cols]\n",
    "doctor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure Dimension\n",
    "Here, the primary key is already given to us with the procedure code. We will keep it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['procedure_code', 'procedure_name']\n",
    "procedure = dv[cols].drop_duplicates()\n",
    "procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing original data with primary keys\n",
    "We can now revisit our original DataFrame and replace all columns in each dimension with a single column, the primary key of that dimension.\n",
    "\n",
    "### Join original table to dimension tables\n",
    "To make the replacement, we will join our original table to each one of our dimension tables. The **`merge`** method joins tables together in Pandas. We can specify how the tables will join with the **`on`** parameter. We will join on all the non-primary key columns. Below, we join the **`patient`** table. The result is one extra column at the end of the DataFrame, the **`patient_id`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_fact = dv.merge(patient, on=['patient_name', 'patient_address', 'patient_birthdate'])\n",
    "dv_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the dimension columns\n",
    "We can now drop all the original patient columns as the **`patient_id`** now refers to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_fact = dv_fact.drop(columns=['patient_name', 'patient_address', 'patient_birthdate'])\n",
    "dv_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace all the other dimensions with primary key columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doctor Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_fact = dv_fact.merge(doctor, on=['doctor_name', 'doctor_specialty'])\n",
    "dv_fact = dv_fact.drop(columns=['doctor_name', 'doctor_specialty'])\n",
    "dv_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinic Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_fact = dv_fact.merge(clinic, on=['clinic_name', 'clinic_address'])\n",
    "dv_fact = dv_fact.drop(columns=['clinic_name', 'clinic_address'])\n",
    "dv_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure Dimension\n",
    "Since the primary key is already in the table, we can just drop the **`procedure_name`** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_fact = dv_fact.drop(columns=['procedure_name'])\n",
    "dv_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrange columns with foreign keys first\n",
    "When a primary key from table is found in another table, it is called a **foreign key**. Foreign keys can repeat in the table they are in. Primary keys, however, can never repeat in the tables they are in. This is a very important property. Foreign keys are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['patient_id', 'clinic_id', 'doctor_id', \n",
    "        'procedure_code', 'visit_date', 'cost']\n",
    "dv_fact = dv_fact[cols]\n",
    "dv_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact Table\n",
    "This last DataFrame, **`dv_fact`** is called a **fact table** using database terminology. Fact tables hold the actual **events** or **transactions** that take place in a business. They hold the columns that are subject to change such as date and cost here. If we had data from a grocery store, our fact table would have columns like the number of items purchased, the cost of each item, and the type of payment used.  Fact tables have references to the static dimension tables through foreign keys.\n",
    "\n",
    "## Data Model Diagram\n",
    "The diagram of the **data model** or **entity-relationship diagram** is presented below. Data models show the logical relationships between the fact and dimension tables. This type of data model is called a **star schema** and one of the simplest designs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/doctor_data_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [this simple Stack Overflow answer][1] for another description of fact and dimension tables.\n",
    "\n",
    "[1]: https://stackoverflow.com/a/33750545/3707607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">Tidy the dataset `tidy/store_transactions.csv`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
