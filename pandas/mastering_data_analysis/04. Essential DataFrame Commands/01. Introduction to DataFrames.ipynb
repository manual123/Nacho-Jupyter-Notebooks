{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to DataFrame\n",
    "\n",
    "In the previous part, we covered the most common and fundamental attributes and methods for a Series. This chapter begins our coverage of similar and analogous operations for DataFrames.\n",
    "\n",
    "## DataFrames vs Series\n",
    "\n",
    "DataFrames and Series are extremely similar objects. A Series is just a single dimension of data and is usually formed from a single column of a DataFrame. Series have an index and values but no columns. A DataFrame can be thought of as a collection of Series objects each directly accessible by placing the column name within *just the brackets*.\n",
    "\n",
    "### View the API for a complete list of functionality\n",
    "\n",
    "As we did for Series, it can be helpful to see the entire list of attributes and methods available to DataFrames. Visit the [DataFrame section][1] of the API to see all of its functionality.\n",
    "\n",
    "### Best of DataFrame API\n",
    "\n",
    "DataFrames have an abundance of attributes and methods that do not give any additional functionality to the library. We focus on the core attributes and methods that give you the most power to complete a data analysis.\n",
    "\n",
    "### Minimally Sufficient Pandas\n",
    "\n",
    "As a gentle reminder, it is my opinion that you stick with a minimal subset of pandas when doing an analysis. Using more obscure methods does not make you a better analyst. This is akin to going to a party and using the most obscure and difficult words to impress the guests. The point of a data analysis is to clearly expose the information held within the data. Just about everything that you want to do can be clearly expressed with minimal pandas syntax.\n",
    "\n",
    "### Bikes dataset\n",
    "\n",
    "We will use the bikes dataset to introduce the core attributes and methods of DataFrames.\n",
    "\n",
    "[1]: http://pandas.pydata.org/pandas-docs/stable/reference/frame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bikes = pd.read_csv('../data/bikes.csv', parse_dates=['starttime', 'stoptime'])\n",
    "bikes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core DataFrame Attributes\n",
    "\n",
    "The core DataFrame attributes that you need to know are listed below.\n",
    "\n",
    "* `index`\n",
    "* `columns`\n",
    "* `values`\n",
    "* `dtypes`\n",
    "* `shape`\n",
    "* `size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the index and columns\n",
    "\n",
    "We've discussed the index and columns extensively before this chapter. As a review, the purpose of the index is to label each row, just as the the purpose for the columns is to label each column. The index and columns are not data. They are labels for the data. If no index is set during read, pandas uses the default `RangeIndex` which defines a sequence of integers beginning at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's access the column names with the `columns` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `values` returns a 2-D numpy array\n",
    "The `values` attribute returns a two-dimensional numpy array of all the column values. It is like a DataFrame with no index or columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced discussion on the `values` attribute\n",
    "The `values` attribute always returns a single numpy array which may lead you to the assumption that pandas stores its data as a single numpy array. This isn't the case. pandas has separate two-dimensional numpy arrays for each data type in the DataFrame. For instance, if a DataFrame contains integers, floats, strings, and datetimes, then pandas will have four separate numpy arrays to contain data for each of those data types. The reason for this, is that numpy arrays can only be of one specific data type. In other words, numpy arrays contain **homogeneous** data. The exception to this is the 'object' numpy data type which can contain any Python object.\n",
    "\n",
    "Whenever you access the `values` attribute of a DataFrame, pandas concatenates together all of the numpy arrays together to return a single array. Notice that the data type of the resulting `bikes.values` array is object. This is because the `bikes` DataFrame contains string columns and the only valid numpy data type that contains both numeric and string values is object.\n",
    "\n",
    "If you had a DataFrame consisting only of integers and floats, then the `values` attribute would return an array with a data type of float. pandas always chooses the data type that loses no information when you access the `values` attribute. Below, an integer column (`tripduration`) and a float column (`dpcapacity_start`) are selected and then the `values` attribute is accessed to return a numpy array with a float data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes[['tripduration', 'dpcapacity_start']].values.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `shape` returns a tuple of the number of rows and columns\n",
    "\n",
    "The `shape` attribute returns a Python tuple of length 2 containing the number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = bikes.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the number of rows or columns as an integer by selecting them from the tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It isn't necessary to assign the tuple to a variable beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `size` returns the total number of elements in the DataFrame\n",
    "The `size` attribute is a bit tricky and returns the total number of elements in the DataFrame. This is simply the number of rows multiplied by the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify this by multiplying the number of rows and columns together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape[0] * shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `len` function returns the number of rows\n",
    "Passing in the DataFrame to the built-in Python `len` function returns the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic Operations with a DataFrame\n",
    "\n",
    "We now cover what happens when we use the arithmetic operators `+`, `-`, `*`, `/`, `**`, `//`, `%` on a DataFrame. Let's say we have DataFrame, `df`, and execute `df + 5`. pandas attempts to add 5 to each value in the DataFrame. This operation only completes if all the columns are numeric (or boolean).\n",
    "\n",
    "### Attempt to add 5 to bikes\n",
    "\n",
    "If we attempt to add 5 to `bikes` we get an error as we have a mix of numeric, object, and datetime columns. Adding the integer 5 to a string is impossible and a `TypeError` is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only numeric data with `select_dtypes`\n",
    "DataFrames have a method unique to them called `select_dtypes` which selects a subset of columns with the passed type. Pass it the data type you want to select as a string. For example, pass it the string 'int' to select all integer columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.select_dtypes('int').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the string 'number' to select all numeric data\n",
    "pandas offers a shortcut to select all numeric data types (integers and floats) with the string 'number'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_number = bikes.select_dtypes('number')\n",
    "bikes_number.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 5 to `bikes_number`\n",
    "\n",
    "Now that we have a DataFrame consisting entirely of numeric data we can successfully add 5 to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bikes_number + 5).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition and multiplication with string columns\n",
    "\n",
    "Addition actually works with strings by appending the word being added to each value. You can also use multiplication to concatenate each string value to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bikes.select_dtypes('object') + ' SOMESTRING').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bikes.select_dtypes('object') * 3).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Operators with DataFrames\n",
    "\n",
    "The comparison operators (`<`, `<=`, `>`, `>=`, `==`, `!=`) work similarly to the arithmetic ones and return a DataFrame of all boolean columns. Here, we test whether every value in the DataFrame is greater than 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bikes_number > 5).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take care when working with the entire DataFrame\n",
    "\n",
    "When you perform one of the above operations, you are applying that operation to every value in the DataFrame. Make sure this is what you want because all values will be affected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap of DataFrame and Series methods\n",
    "\n",
    "Most of the methods that exist for Series also exist for DataFrames and vice-versa. This is good news as it would be a huge hassle to have a different set of methods for such similar objects. In this section, we find all the attributes and methods that are either in-common or unique to Series and DataFrames. We begin by using a set comprehension to get all of the public (those that don't begin with an underscore) attributes and methods for each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_public = {method for method in dir(pd.DataFrame) if not method.startswith('_')}\n",
    "series_public = {method for method in dir(pd.Series) if not method.startswith('_')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the total number of methods for each type. Notice how they have nearly the same amount:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_public), len(series_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the number of methods in common. The ampersand computes the intersection between sets. About 90% of the attributes and methods are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_public & series_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes and methods unique to DataFrames\n",
    "\n",
    "The minus sign computes the difference between sets. It removes all the elements of the second set from the first. Below we return the attributes and methods unique to DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_public - series_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the methods unique to Series\n",
    "\n",
    "Reversing the operation returns the attributes and methods unique to Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(series_public - df_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionaries\n",
    "\n",
    "A data dictionary is an important element of a data analysis and at a minimum gives us the column name and description of each column. Other information on each column can be kept in it such as the data type of each column or number of missing values.\n",
    "\n",
    "The college dataset has a data dictionary available that can be read in as a DataFrame. It contains the descriptions of each column, which is important with this dataset as the column names are not easily decipherable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are more than 20 (the default) columns\n",
    "pd.set_option('display.max_columns', 40) \n",
    "college = pd.read_csv('../data/college.csv', index_col='instnm')\n",
    "college.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dictionary is a CSV, which can be read in as a DataFrame to help understand the information in the college DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/dictionaries/college_data_dictionary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">Select only the float columns from the `college` DataFrame. How many are there?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">When you call the `info` method on a DataFrame, one of the very last items that gets outputted is the count of columns for each data type. Can you think of a different combination of pandas operations that would return this as a Series.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
